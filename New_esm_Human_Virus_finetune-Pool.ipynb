{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_5w39f_fnY9"
   },
   "source": [
    "esm based dynamic model (not using static embeds).\n",
    "\n",
    "\n",
    "Use TF:\n",
    "*  ðŸ‡°https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb#scrollTo=de8419b5\n",
    "* Torch based /Trainer example:  https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb#scrollTo=49dcba23\n",
    "\n",
    "\n",
    "\n",
    "* NOte for pytorch training could use trainer maybe, and mixed precision - https://huggingface.co/docs/transformers/v4.18.0/en/performance#fp16-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kalvvWZZgM0E",
    "outputId": "f575c531-2ec5-4880-fba6-73597c8e58cb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # drive.mount(\"/content/drive/MyDrive/Research/proteins\")\n",
    "# # drive.mount(\"/content/drive/MyDrive/proteins\")\n",
    "\n",
    "# !pip install tensorflow -U -q\n",
    "# !pip install torch accelerate transformers fair-esm datasets  -U -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_cRmHN0j709"
   },
   "source": [
    "* Use the unirpot fasta file I downloaded and uploaded to my drive\n",
    "\n",
    "`/content/drive/MyDrive/Research/biodata/proteins/Transmembrane_human_90.fasta`\n",
    "\n",
    "* Download fasta from: `https://www.uniprot.org/uniref/?query=uniprot:(keyword%3A%22Transmembrane+%5BKW-0812%5D%22+AND+organism%3A%22Homo+sapiens+%28Human%29+%5B9606%5D%22)+identity:0.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kwgVw-CN1OgJ"
   },
   "outputs": [],
   "source": [
    "# DATA_PATH = \"/content/drive/MyDrive/Research/biodata/proteins/membrane_100_whole_protbert_embed.snappy.parquet\"\n",
    "# DATA_PATH = \"/content/drive/MyDrive/Research/CIDR-Protein Anomalies project/protein_anomalies_data/swp_human_viri_all_embed_esm.parquet\" ## ESM1B embedding (max len 1022)\n",
    "# DATA_PATH = \"/content/drive/MyDrive/proteins/New Protein-Virus anom project/hum_vir_swp-globalEmbed-train.csv.gz\"## TRAIN\n",
    "DATA_PATH = \"hum_vir_swp-train.csv.gz\"## TRAIN\n",
    "\n",
    "## TEST data:\n",
    "# TEST_DATA_PATH = \"/content/drive/MyDrive/proteins/New Protein-Virus anom project/hum_vir_swp-globalEmbed-test.csv.gz\"## TRAIN\n",
    "TEST_DATA_PATH = \"hum_vir_swp-test.csv.gz\"## TEST\n",
    "\n",
    "# ## metadata for all reviewed/swissprot human + virus proteins\n",
    "# METADATA_PATH = \"/content/drive/MyDrive/Research/CIDR-Protein Anomalies project/protein_anomalies_data/SWP_human_viruses_all.xlsx\"\n",
    "\n",
    "TARGET_COL = \"virus\" ## use for filtering data into 1 class\n",
    "\n",
    "MAX_LEN = 512 # exclude sequences longer than this. (Not merely truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZrxD5vg90QoW"
   },
   "outputs": [],
   "source": [
    "# MY_FASTA_PATH = \"/content/drive/MyDrive/Research/biodata/proteins/Transmembrane_human_90.fasta\" # 14k sequences, with fragments, 90% id redundnancy\n",
    "\n",
    "# MY_FASTA_PATH = \"/content/drive/MyDrive/Research/biodata/proteins/Transmembrane_human_whole_100.fasta\" # 30K sequences, without fragments\n",
    "# MY_FASTA_PATH = \"Transmembrane_human_whole_90.fasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa-7WUuSfnZC"
   },
   "source": [
    "# Embed sequences in a FASTA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKw7JD3_fnZD",
    "outputId": "79159032-8099-4c16-b409-94eb74b0d371"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 12:43:55.211292: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-29 12:43:55.291922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-29 12:43:55.918048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_17514/3407002226.py:22: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# from bio_embeddings.embed import ProtTransBertBFDEmbedder\n",
    "# from Bio import SeqIO\n",
    "import torch\n",
    "import esm\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC as tf_auc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "# from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing  import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "# from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "## https://huggingface.co/docs/transformers/perf_train_gpu_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JeQ7KgVEggg-"
   },
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tensorflow.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uw-akVUtYsvZ"
   },
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_global_policy(policy)\n",
    "# tensorflow.keras.mixed_precision.set_global_policy('mixed_float16') # causes error with our pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rWVA7azNfnZE"
   },
   "outputs": [],
   "source": [
    "# embedder = ProtTransBertBFDEmbedder(half_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Eggiq94CubAw",
    "outputId": "f4902346-b160-4efc-98cd-0bf7dad2de16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>virus</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cluster name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MADFLKGLPVYNKSNFSRFHADSVCKASNRRPSVYLPTREYPSEQI...</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>Cluster: DET1- and DDB1-associated protein 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MPSTLQVLAKKVLALEHKENDHISREYYYHILKCCGLWWHEAPIIL...</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "      <td>Cluster: Protein MGF 360-19R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MASSAELDFNLQALLEQLSQDELSKFKSLIRTISLGKELQTVPQTE...</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>Cluster: Pyrin domain-containing protein 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAAWGKKHAGKDPVRDECEERNRFTETREEDVTDEHGEREPFAETD...</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>Cluster: Protein FAM9B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASDSPARSLDEIDLSALRDPAGIFELVELVGNGTYGQVYKGRHVK...</td>\n",
       "      <td>0</td>\n",
       "      <td>1360</td>\n",
       "      <td>Cluster: TRAF2 and NCK-interacting protein kinase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20335</th>\n",
       "      <td>MDPDKQDALNSIENSIYRTAFKLQSVQTLCQLDLIDSSLIQQVLLR...</td>\n",
       "      <td>0</td>\n",
       "      <td>578</td>\n",
       "      <td>Cluster: Dystrotelin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20336</th>\n",
       "      <td>MLCPWRTANLGLLLILTIFLVAEAEGAAQPNNSLMLQTSKENHALA...</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>Cluster: Cell surface glycoprotein CD200 recep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20337</th>\n",
       "      <td>MCLRFFSPVPGSTSSATNVTMVVSAGPWSSEKAEMNILEINEKLRP...</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "      <td>Cluster: Putative neuroblastoma breakpoint fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20338</th>\n",
       "      <td>MASHAGQQHAPAFGQAARASGPTDGRAASRPSHRQGASEARGDPEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>376</td>\n",
       "      <td>Cluster: Thymidine kinase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20339</th>\n",
       "      <td>MSASSLLEQRPKGQGNKVQNGSVHQKDGLNDDDFEPYLSPQARPNN...</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "      <td>Cluster: YTH domain-containing family protein 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20340 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sequence  virus  Length  \\\n",
       "0      MADFLKGLPVYNKSNFSRFHADSVCKASNRRPSVYLPTREYPSEQI...      0     102   \n",
       "1      MPSTLQVLAKKVLALEHKENDHISREYYYHILKCCGLWWHEAPIIL...      1     362   \n",
       "2      MASSAELDFNLQALLEQLSQDELSKFKSLIRTISLGKELQTVPQTE...      0      97   \n",
       "3      MAAWGKKHAGKDPVRDECEERNRFTETREEDVTDEHGEREPFAETD...      0     186   \n",
       "4      MASDSPARSLDEIDLSALRDPAGIFELVELVGNGTYGQVYKGRHVK...      0    1360   \n",
       "...                                                  ...    ...     ...   \n",
       "20335  MDPDKQDALNSIENSIYRTAFKLQSVQTLCQLDLIDSSLIQQVLLR...      0     578   \n",
       "20336  MLCPWRTANLGLLLILTIFLVAEAEGAAQPNNSLMLQTSKENHALA...      0     348   \n",
       "20337  MCLRFFSPVPGSTSSATNVTMVVSAGPWSSEKAEMNILEINEKLRP...      0     421   \n",
       "20338  MASHAGQQHAPAFGQAARASGPTDGRAASRPSHRQGASEARGDPEL...      1     376   \n",
       "20339  MSASSLLEQRPKGQGNKVQNGSVHQKDGLNDDDFEPYLSPQARPNN...      0     579   \n",
       "\n",
       "                                            Cluster name  \n",
       "0           Cluster: DET1- and DDB1-associated protein 1  \n",
       "1                           Cluster: Protein MGF 360-19R  \n",
       "2             Cluster: Pyrin domain-containing protein 2  \n",
       "3                                 Cluster: Protein FAM9B  \n",
       "4      Cluster: TRAF2 and NCK-interacting protein kinase  \n",
       "...                                                  ...  \n",
       "20335                               Cluster: Dystrotelin  \n",
       "20336  Cluster: Cell surface glycoprotein CD200 recep...  \n",
       "20337  Cluster: Putative neuroblastoma breakpoint fam...  \n",
       "20338                          Cluster: Thymidine kinase  \n",
       "20339    Cluster: YTH domain-containing family protein 2  \n",
       "\n",
       "[20340 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_parquet(DATA_PATH) # numpy to pandas\n",
    "df = pd.read_csv(DATA_PATH,usecols=[\"Sequence\",\"virus\",\"Length\",\"Cluster name\"])\n",
    "df_test = pd.read_csv(TEST_DATA_PATH,usecols=[\"Sequence\",\"virus\",\"Length\",\"Cluster name\"])\n",
    " ## lengths of all the seqs\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fkeYBgfafVoy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14668.0</td>\n",
       "      <td>473.16</td>\n",
       "      <td>308.52</td>\n",
       "      <td>11.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>1533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5672.0</td>\n",
       "      <td>380.31</td>\n",
       "      <td>298.35</td>\n",
       "      <td>11.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>1520.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count    mean     std   min    25%    50%    75%     max\n",
       "virus                                                            \n",
       "0      14668.0  473.16  308.52  11.0  244.0  398.0  623.0  1533.0\n",
       "1       5672.0  380.31  298.35  11.0  151.0  297.0  514.0  1520.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"virus\"])[\"Length\"].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rm2Ms4BmQ4wn",
    "outputId": "3cd408f3-b45e-4bcd-ec67-604d441fe4e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean         0.28\n",
      "sum       5672.00\n",
      "count    20340.00\n",
      "Name: virus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"virus\"].agg([\"mean\",\"sum\",\"count\"]).round(2))\n",
    "# df[\"Length\"].describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNDVeR2vQ9YZ",
    "outputId": "6b144341-817f-4ea9-82e5-242fb54639ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4777.0\n",
       "mean      444.3\n",
       "std       304.5\n",
       "min        18.0\n",
       "25%       212.0\n",
       "50%       369.0\n",
       "75%       589.0\n",
       "max      1534.0\n",
       "Name: Length, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Length\"].describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8VNnHUwRQRm",
    "outputId": "d46999a0-aadf-4a25-8b74-af46363b26e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    13727.0\n",
      "mean       272.9\n",
      "std        128.4\n",
      "min         11.0\n",
      "25%        161.0\n",
      "50%        269.0\n",
      "75%        376.0\n",
      "max        512.0\n",
      "Name: Length, dtype: float64\n",
      "mean         0.31\n",
      "sum       4247.00\n",
      "count    13727.00\n",
      "Name: virus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[df[\"Length\"]<=MAX_LEN].reset_index(drop=True)\n",
    "df_test = df_test.loc[df_test[\"Length\"]<=MAX_LEN].reset_index(drop=True)\n",
    "\n",
    "print(df[\"Length\"].describe().round(1))\n",
    "print(df[\"virus\"].agg([\"mean\",\"sum\",\"count\"]).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PcMwJBkUov07"
   },
   "outputs": [],
   "source": [
    "# ## metadata about all sequences, can be used to identify and to define targets/labels\n",
    "# df_meta = pd.read_excel(METADATA_PATH).dropna(how=\"all\",axis=1)\n",
    "# df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSXy_OzjhIB7"
   },
   "source": [
    "### example pretrained fb/torch:\n",
    "* https://github.com/facebookresearch/esm#getting-started-with-this-repo-\n",
    "\n",
    "* Transformers + trainer example : (mlm case): https://github.com/facebookresearch/esm/discussions/556\n",
    "* keras models supported / via HF?\n",
    "  * https://huggingface.co/docs/transformers/model_doc/esm#transformers.EsmForSequenceClassification.forward.example\n",
    "\n",
    "\n",
    "  TF finetuning example (sequence evel?):\n",
    "  https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb#scrollTo=4b26b828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CDdMQ98rii9t"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AdamWeightDecay\n",
    "from tensorflow.keras.optimizers import Adafactor, Adam # more memory effecient than adamWD\n",
    "import tensorflow\n",
    "# from tensorflow.keras.metrics.AUC()\n",
    "# from transformers import AutoTokenizer #DataCollatorForLanguageModeling,\n",
    "## https://huggingface.co/docs/transformers/model_doc/esm#transformers.EsmForSequenceClassification.forward.example\n",
    "from transformers import AutoTokenizer, EsmForSequenceClassification, Trainer, TFAutoModel\n",
    "from transformers import TFAutoModelForTokenClassification, TFAutoModelForSequenceClassification ,TFEsmForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mzH6SlkfBrfZ"
   },
   "outputs": [],
   "source": [
    "# sequences = df[\"Sequence\"].tolist()\n",
    "# labels = df[\"virus\"].tolist()\n",
    "# groups = df[\"Cluster name\"].tolist()\n",
    "\n",
    "# assert len(sequences) == len(labels) # Quick check to make sure we got it right\n",
    "\n",
    "# train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)#,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rR9-cKgPjzW2"
   },
   "outputs": [],
   "source": [
    "train_sequences = df[\"Sequence\"].tolist()\n",
    "train_labels = df[\"virus\"].tolist()\n",
    "train_groups = df[\"Cluster name\"].tolist()\n",
    "\n",
    "# train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)#,stratify=labels)\n",
    "\n",
    "test_sequences = df_test[\"Sequence\"].tolist()\n",
    "test_labels = df_test[\"virus\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_KUug1Lh5bH",
    "outputId": "8249a98b-2849-49bc-8610-c7216fb44b9e"
   },
   "outputs": [],
   "source": [
    "# # Load ESM-2 model\n",
    "# ## smallest: esm2_t6_8M_UR50D\n",
    "# ## 2d smallest\n",
    "# ## large: esm2_t33_650M_UR50D\n",
    "# # model_checkpoint =  \"facebook/esm2_t12_35M_UR50D\"#\"facebook/esm2_t6_8M_UR50D\"\n",
    "# model_checkpoint =  \"facebook/esm2_t30_150M_UR50D\"\n",
    "#  # ElnaggarLab/ankh-base\n",
    "#  ### https://github.com/agemagician/Ankh/blob/main/examples/binary_classification_solubility_task.ipynb - different model?\n",
    "#  #  https://github.com/agemagician/Ankh#models   - 450M model size\n",
    "# # model_checkpoint =   \"ElnaggarLab/ankh-base\"\n",
    "\n",
    "# model_max_len = min(800,MAX_LEN)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, padding=True, truncation=True,max_length=model_max_len)\n",
    "\n",
    "# num_labels = max(train_labels + test_labels) #+ 1  # Add 1 since 0 can be a label\n",
    "# print(\"Num labels:\", num_labels)\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels,problem_type=\"single_label_classification\") # worked, orig\n",
    "# # model = EsmForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "# # model = TFEsmForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels,problem_type=\"single_label_classification\")\n",
    "\n",
    "# # model.eval()  # disables dropout for deterministic results # from original - in infer/embed only example\n",
    "\n",
    "# # last_layer_num = model.num_layers ## 33 for esm2_t33_650M_UR50D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 12:45:28.565627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFEsmModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'esm.embeddings.position_embeddings.weight', 'esm.embeddings.position_ids', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing TFEsmModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFEsmModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFEsmModel were not initialized from the PyTorch model and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 12:45:33.630760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [13727,512]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-08-29 12:45:33.630902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32 and shape [13727,512]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "/home/ddofer/anaconda3/lib/python3.10/site-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['attention_mask'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_esm_model/esm/pooler/dense/kernel:0', 'tf_esm_model/esm/pooler/dense/bias:0', 'tf_esm_model/esm/contact_head/regression/kernel:0', 'tf_esm_model/esm/contact_head/regression/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_esm_model/esm/pooler/dense/kernel:0', 'tf_esm_model/esm/pooler/dense/bias:0', 'tf_esm_model/esm/contact_head/regression/kernel:0', 'tf_esm_model/esm/contact_head/regression/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_esm_model/esm/pooler/dense/kernel:0', 'tf_esm_model/esm/pooler/dense/bias:0', 'tf_esm_model/esm/contact_head/regression/kernel:0', 'tf_esm_model/esm/contact_head/regression/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_esm_model/esm/pooler/dense/kernel:0', 'tf_esm_model/esm/pooler/dense/bias:0', 'tf_esm_model/esm/contact_head/regression/kernel:0', 'tf_esm_model/esm/contact_head/regression/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 12:45:58.348080: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0xea09b360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-29 12:45:58.348103: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4080, Compute Capability 8.9\n",
      "2023-08-29 12:45:58.351333: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-29 12:45:58.469214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2023-08-29 12:45:58.537726: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n",
      "2023-08-29 12:45:58.582138: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2746/2746 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.8823 - auc: 0.8838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:00:24.084160: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [3231]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2746/2746 [==============================] - 986s 343ms/step - loss: 0.0706 - accuracy: 0.8823 - auc: 0.8838 - val_loss: 0.0491 - val_accuracy: 0.9226 - val_auc: 0.9233\n",
      "Epoch 2/5\n",
      "2746/2746 [==============================] - 940s 342ms/step - loss: 0.0395 - accuracy: 0.9415 - auc: 0.9596 - val_loss: 0.0413 - val_accuracy: 0.9375 - val_auc: 0.9654\n",
      "Epoch 3/5\n",
      "2746/2746 [==============================] - 945s 344ms/step - loss: 0.0248 - accuracy: 0.9666 - auc: 0.9814 - val_loss: 0.0464 - val_accuracy: 0.9409 - val_auc: 0.9634\n",
      "Epoch 4/5\n",
      "2746/2746 [==============================] - 945s 344ms/step - loss: 0.0150 - accuracy: 0.9804 - auc: 0.9920 - val_loss: 0.0508 - val_accuracy: 0.9328 - val_auc: 0.9592\n",
      "Epoch 5/5\n",
      "2746/2746 [==============================] - 940s 342ms/step - loss: 0.0115 - accuracy: 0.9850 - auc: 0.9941 - val_loss: 0.0463 - val_accuracy: 0.9387 - val_auc: 0.9657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f009e974a00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## from transformers import AutoTokenizer, TFAutoModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, GlobalMaxPooling1D, GlobalAveragePooling1D, Concatenate, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_checkpoint = \"facebook/esm2_t30_150M_UR50D\"#\"facebook/esm2_t6_8M_UR50D\"  # Replace with your pre-trained model checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Parameters\n",
    "model_max_len = MAX_LEN\n",
    "batch_size_train = 5\n",
    "batch_size_test = 5\n",
    "learning_rate = 8e-5\n",
    "num_labels = 1  # Replace with the number of unique labels in your dataset\n",
    "\n",
    "# Tokenize the sequences\n",
    "train_tokenized = tokenizer(train_sequences, padding=True, truncation=True, max_length=model_max_len)\n",
    "test_tokenized = tokenizer(test_sequences, padding=True, truncation=True, max_length=model_max_len)\n",
    "\n",
    "# Convert to TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_tokenized),\n",
    "    train_labels\n",
    ")).batch(batch_size_train).shuffle(buffer_size=len(train_sequences))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_tokenized),\n",
    "    test_labels\n",
    ")).batch(batch_size_test)\n",
    "\n",
    "## added. (Awhat about add col labels?)\n",
    "train_dataset = train_dataset.map(lambda x, y: ({'input_layer': x['input_ids'], 'attention_mask': x['attention_mask']}, y))\n",
    "test_dataset = test_dataset.map(lambda x, y: ({'input_layer': x['input_ids'], 'attention_mask': x['attention_mask']}, y))\n",
    "\n",
    "# Load the pre-trained transformer model\n",
    "base_model = TFAutoModel.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Freeze all layers except the last few\n",
    "for layer in base_model.layers[2:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "input_layer = Input(shape=(model_max_len,), dtype=tf.int32, name='input_layer')\n",
    "sequence_output = base_model(input_layer)[0]\n",
    "\n",
    "# Add GlobalMeanPooling1D and GlobalMaxPooling1D\n",
    "avg_pool = GlobalAveragePooling1D()(sequence_output)\n",
    "max_pool = GlobalMaxPooling1D()(sequence_output)\n",
    "concat = Concatenate()([avg_pool, max_pool])\n",
    "concat = Dropout(0.15)(concat)\n",
    "\n",
    "# # Initialize mixed precision training\n",
    "# from tensorflow.keras import mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_global_policy(policy)\n",
    "\n",
    "\n",
    "# Add output layer for binary classification\n",
    "output = Dense(1, activation='sigmoid', dtype='float32')(concat)  # Ensuring the dtype is float32 for the output layer\n",
    "\n",
    "# Compile model\n",
    "final_model = Model(inputs=input_layer, outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = \"BinaryFocalCrossentropy\"#tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "final_model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\",tf.keras.metrics.AUC(num_thresholds=10,from_logits=True)])\n",
    "\n",
    "# Train the model\n",
    "final_model.fit(train_dataset, validation_data=test_dataset, epochs=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEcix1ZWfQg-"
   },
   "source": [
    "With 35M model :\n",
    "```\n",
    "Default (1024) max length\n",
    "batch_size=8\n",
    "\n",
    "opt = Adafactor(1e-4)##AdamWeightDecay(1e-4) #default: AdamWeightDecay(2e-5)\n",
    "model.compile(optimizer=opt, metrics=[\"accuracy\"],\n",
    "              loss=\"BinaryCrossentropy\")\n",
    "3813/3813 [==============================] - 2625s 661ms/step - loss: 0.2452 - accuracy: 0.9104 - val_loss: 0.1622 - val_accuracy: 0.9363\n",
    "Epoch 2/3\n",
    "3813/3813 [==============================] - 2518s 661ms/step - loss: 0.1218 - accuracy: 0.9597 - val_loss: 0.1533 - val_accuracy: 0.9463\n",
    "Epoch 3/3\n",
    "3813/3813 [==============================] - 2523s 662ms/step - loss: 0.0730 - accuracy: 0.9799 - val_loss: 0.1978 - val_accuracy: 0.9436\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TgVhQQzYgy23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.embedding.Embedding object at 0x7f010bedc2e0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 14:04:56.443629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n",
      "2023-08-29 14:04:59.482038: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n",
      "2023-08-29 14:04:59.714421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids_1' with dtype int32 and shape [?,?]\n",
      "\t [[{{node input_ids_1}}]]\n",
      "2023-08-29 14:04:59.933222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n",
      "2023-08-29 14:05:00.159073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids_1' with dtype int32 and shape [?,?]\n",
      "\t [[{{node input_ids_1}}]]\n",
      "2023-08-29 14:05:00.387117: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n",
      "2023-08-29 14:05:00.597812: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n",
      "2023-08-29 14:05:00.828331: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n",
      "2023-08-29 14:05:01.070512: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids_1' with dtype int32 and shape [?,?]\n",
      "\t [[{{node input_ids_1}}]]\n",
      "2023-08-29 14:05:01.297842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids_1' with dtype int32 and shape [?,?]\n",
      "\t [[{{node input_ids_1}}]]\n",
      "2023-08-29 14:05:05.400862: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_layer' with dtype int32 and shape [?,512]\n",
      "\t [[{{node input_layer}}]]\n",
      "2023-08-29 14:05:08.369236: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_layer' with dtype int32 and shape [?,512]\n",
      "\t [[{{node input_layer}}]]\n",
      "2023-08-29 14:05:08.599593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype int32 and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-29 14:05:08.836407: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_layer' with dtype int32 and shape [?,512]\n",
      "\t [[{{node input_layer}}]]\n",
      "2023-08-29 14:05:09.073135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype int32 and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-29 14:05:09.306122: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_layer' with dtype int32 and shape [?,512]\n",
      "\t [[{{node input_layer}}]]\n",
      "2023-08-29 14:05:09.527548: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids' with dtype int32 and shape [?,512]\n",
      "\t [[{{node input_ids}}]]\n",
      "2023-08-29 14:05:09.768764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids' with dtype int32 and shape [?,512]\n",
      "\t [[{{node input_ids}}]]\n",
      "2023-08-29 14:05:09.795816: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1280]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-29 14:05:10.026234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype int32 and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-29 14:05:10.262095: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype int32 and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-29 14:05:10.620917: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_layer' with dtype int32 and shape [?,512]\n",
      "\t [[{{node input_layer}}]]\n",
      "2023-08-29 14:05:10.938554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype int32 and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-29 14:05:11.168196: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype int32 and shape [?,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-29 14:05:21.124110: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 14:05:21.368006: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n",
      "2023-08-29 14:05:21.613915: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids_attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node input_ids_attention_mask}}]]\n",
      "2023-08-29 14:05:21.850050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids_attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node input_ids_attention_mask}}]]\n",
      "2023-08-29 14:05:22.087099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids' with dtype int32 and shape [?,512]\n",
      "\t [[{{node input_ids}}]]\n",
      "2023-08-29 14:05:22.335331: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_ids' with dtype int32 and shape [?,512]\n",
      "\t [[{{node input_ids}}]]\n",
      "2023-08-29 14:05:39.842399: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1280]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-08-29 14:05:41.150102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n",
      "2023-08-29 14:05:41.333148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'attention_mask' with dtype int32 and shape [?,?]\n",
      "\t [[{{node attention_mask}}]]\n",
      "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 1097). These functions will not be directly callable after loading.\n",
      "2023-08-29 14:05:47.915505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input_layer' with dtype int32 and shape [?,512]\n",
      "\t [[{{node serving_default_input_layer}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_esm_pool.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_esm_pool.tf/assets\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"trained_esm.keras\")\n",
    "model.save(\"trained_esm_pool.tf\",save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(tf_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(test_labels,y_test_pred.logits[:,1]>=0.5))\n",
    "print(classification_report(test_labels,y_test_pred.logits>=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_labels,y_test_pred.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary_preds = (y_test_pred.logits>=0.5).astype(int).ravel()\n",
    "print(len(y_test_binary_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mistakes_mask = test_labels!=y_test_binary_preds\n",
    "print(test_mistakes_mask.sum())\n",
    "print(len(test_mistakes_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[test_mistakes_mask].drop_duplicates(subset=\"Cluster name\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
