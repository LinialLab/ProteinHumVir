{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_5w39f_fnY9"
   },
   "source": [
    "esm based dynamic model (not using static embeds).\n",
    "\n",
    "+ Use HF Trainer, LORA:\n",
    "  * https://huggingface.co/blog/AmelieSchreiber/esmbind\n",
    "\n",
    "Use TF:\n",
    "*  🇰https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb#scrollTo=de8419b5\n",
    "* Torch based /Trainer example:  https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb#scrollTo=49dcba23\n",
    "\n",
    "\n",
    "\n",
    "* NOte for pytorch training could use trainer maybe, and mixed precision - https://huggingface.co/docs/transformers/v4.18.0/en/performance#fp16-training\n",
    "\n",
    "\n",
    "* QLORA finetuning: https://huggingface.co/blog/AmelieSchreiber/esm2-ptm\n",
    "  * https://huggingface.co/blog/AmelieSchreiber/esmbind   (token level)\n",
    "\n",
    "* Another lora, qlora example - may use too much mem/bug : https://github.com/huggingface/peft/issues/1023\n",
    "* Default trainer (`AutoModelForSequenceClassification`) + Lora https://huggingface.co/docs/peft/task_guides/image_classification_lora\n",
    "   * seq cls with lora - maybe `task_type=\"SEQ_CLS\"` ? https://github.com/huggingface/peft/blob/main/docs/source/task_guides/ptuning-seq-classification.md\n",
    "* https://www.kaggle.com/code/andregrbnr/protein-sequence-classification - lora modules to save ??\n",
    "\n",
    "  * ESM2-Lora mem bug (also accel data loop) ? https://github.com/huggingface/peft/issues/1023\n",
    "\n",
    "\n",
    "* QLORA: https://huggingface.co/blog/AmelieSchreiber/esm2-ptm\n",
    "  * `36 batch size` with esm-150M !\n",
    "\n",
    "* lora peft - classifier layer weight saving issue?  https://github.com/huggingface/peft/issues/577\n",
    "\n",
    "https://github.com/huggingface/transformers/issues/27702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3049,
     "status": "ok",
     "timestamp": 1706644628798,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "kalvvWZZgM0E",
    "outputId": "f323c22c-784c-4935-ef81-4b61183e3a3d"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GO4tbwSU1pa9"
   },
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge google-colab -y\n",
    "\n",
    "# !pip install tensorflow  -U -q # ankh\n",
    "\n",
    "# !pip install torch  -U -q # fair-esm # seqeval\n",
    "# !pip3 install transformers peft accelerate datasets evaluate bitsandbytes -U -q # --user\n",
    "# !pip install peft bitsandbytes -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_cRmHN0j709"
   },
   "source": [
    "* Use the unirpot fasta file I downloaded and uploaded to my drive\n",
    "\n",
    "`/content/drive/MyDrive/Research/biodata/proteins/Transmembrane_human_90.fasta`\n",
    "\n",
    "* Download fasta from: `https://www.uniprot.org/uniref/?query=uniprot:(keyword%3A%22Transmembrane+%5BKW-0812%5D%22+AND+organism%3A%22Homo+sapiens+%28Human%29+%5B9606%5D%22)+identity:0.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kwgVw-CN1OgJ"
   },
   "outputs": [],
   "source": [
    "#### DATA_PATH = \"/content/drive/MyDrive/Research/CIDR-Protein Anomalies project/protein_anomalies_data/swp_human_viri_all_embed_esm.parquet\" ## ESM1B embedding (max len 1022)\n",
    "# DATA_PATH = \"/content/drive/MyDrive/proteins/New Protein-Virus anom project/hum_vir_swp-globalEmbed-train.csv.gz\"## TRAIN\n",
    "# DATA_PATH = \"/content/drive/MyDrive/hum_vir_swp-globalEmbed-train.csv.gz\"\n",
    "# DATA_PATH = \"/kaggle/input/humvir-proteins/hum_vir_swp-globalEmbed-train.csv/hum_vir_swp-globalEmbed-train.csv\"\n",
    "DATA_PATH = \"hum_vir_swp-globalEmbed-train.csv.gz\"\n",
    "\n",
    "## TEST data:\n",
    "# TEST_DATA_PATH = \"/content/drive/MyDrive/proteins/New Protein-Virus anom project/hum_vir_swp-globalEmbed-test.csv.gz\"## TRAIN\n",
    "# TEST_DATA_PATH = \"/content/drive/MyDrive/hum_vir_swp-globalEmbed-test.csv.gz\"\n",
    "# TEST_DATA_PATH = \"/kaggle/input/humvir-proteins/hum_vir_swp-globalEmbed-test.csv/hum_vir_swp-globalEmbed-test.csv\"\n",
    "TEST_DATA_PATH = \"hum_vir_swp-globalEmbed-test.csv.gz\"\n",
    "\n",
    "# ## metadata for all reviewed/swissprot human + virus proteins\n",
    "# METADATA_PATH = \"/content/drive/MyDrive/Research/CIDR-Protein Anomalies project/protein_anomalies_data/SWP_human_viruses_all.xlsx\"\n",
    "\n",
    "TARGET_COL = \"virus\" ## use for filtering data into 1 class\n",
    "\n",
    "MAX_LEN = 768#1024#768#530 # exclude sequences longer than this. (Not merely truncate)\n",
    "\n",
    "FAST_RUN = True\n",
    "SAVE_MODEL = True#False#True\n",
    "\n",
    "\n",
    "# MODEL_DRIVE_SAVE_PATH = \"/content/drive/MyDrive/proteins/New Protein-Virus anom project/trained_esm_lora_trainer_model\"\n",
    "MODEL_DRIVE_SAVE_PATH = \"150_esm_lora_trainer_model\"\n",
    "# MODEL_DRIVE_SAVE_PATH = \"/kaggle/input/humvir-proteins/qlora/qlora\" # saved + reuploadedon kaggle\n",
    "\n",
    "TRAIN_MODEL = True#False\n",
    "LOAD_TRAINED =  True#False# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZrxD5vg90QoW"
   },
   "outputs": [],
   "source": [
    "# MY_FASTA_PATH = \"/content/drive/MyDrive/Research/biodata/proteins/Transmembrane_human_90.fasta\" # 14k sequences, with fragments, 90% id redundnancy\n",
    "\n",
    "# MY_FASTA_PATH = \"/content/drive/MyDrive/Research/biodata/proteins/Transmembrane_human_whole_100.fasta\" # 30K sequences, without fragments\n",
    "# MY_FASTA_PATH = \"Transmembrane_human_whole_90.fasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa-7WUuSfnZC"
   },
   "source": [
    "# Embed sequences in a FASTA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 11612,
     "status": "ok",
     "timestamp": 1706644666124,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "hKw7JD3_fnZD",
    "outputId": "ffa04bad-8a62-447c-f1cd-466ebec4c602"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 21:17:01.591015: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-14 21:17:01.612514: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-14 21:17:01.612542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-14 21:17:01.613156: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-14 21:17:01.616709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-14 21:17:02.089915: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_4215/3556677317.py:19: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# from bio_embeddings.embed import ProtTransBertBFDEmbedder\n",
    "# from Bio import SeqIO\n",
    "import torch\n",
    "# import esm\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "# from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing  import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "# from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "# from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "## https://huggingface.co/docs/transformers/perf_train_gpu_one\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AdamWeightDecay\n",
    "# from tensorflow.keras.optimizers import Adafactor, Adam # more memory effecient than adamWD\n",
    "# import tensorflow\n",
    "# from tensorflow.keras.metrics.AUC()\n",
    "# from transformers import AutoTokenizer #DataCollatorForLanguageModeling,\n",
    "## https://huggingface.co/docs/transformers/model_doc/esm#transformers.EsmForSequenceClassification.forward.example\n",
    "from transformers import AutoTokenizer, EsmForSequenceClassification, Trainer\n",
    "from transformers import TFAutoModelForSequenceClassification ,TFEsmForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import AutoPeftModelForSequenceClassification, AutoPeftModel\n",
    "\n",
    "## could use transformer pipeline for inference;\n",
    "import datasets\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "# pipe = pipeline(\"text-classification\", model=\"facebook/wav2vec2-base-960h\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(mode=\"disabled\")\n",
    "# alt \n",
    "# wandb.init(project='qlora_humvir')# ; or args = TrainingArguments(report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r8gFb91iUc8N"
   },
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "# # Use the accelerator\n",
    "# ### try disabling? (with qlora)\n",
    "# # accelerator = Accelerator()# trying this\n",
    "# # שבבקךקרשאםר צשטנק בשודקד ןדדוקד?\n",
    "accelerator = Accelerator(mixed_precision=\"fp16\") #bf16\") # fp16 # orig used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "H1bosQnEwXvf"
   },
   "outputs": [],
   "source": [
    "num_epochs = 3#4\n",
    "bch_size = 16#36#32#8#3#2\n",
    "\n",
    "# opt = Adafactor(3e-4)##AdamWeightDecay(1e-4) #default: AdamWeightDecay(2e-5)\n",
    "# opt = AdamWeightDecay(5e-4)#(1e-3)\n",
    "# opt = Adam(8e-4)\n",
    "\n",
    "if FAST_RUN:\n",
    "    num_epochs = 2\n",
    "    # bch_size = 16\n",
    "    bch_size = 32#32\n",
    "    MAX_LEN = int(MAX_LEN//1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dEGNJ6xlxQvC"
   },
   "outputs": [],
   "source": [
    "# model_checkpoint =\"facebook/esm2_t6_8M_UR50D\"\n",
    "# model_checkpoint =  \"facebook/esm2_t12_35M_UR50D\"\n",
    "model_checkpoint =  \"facebook/esm2_t30_150M_UR50D\"\n",
    "# model_checkpoint =  \"facebook/esm2_t33_650M_UR50D\"\n",
    "\n",
    "if FAST_RUN:\n",
    "    # model_checkpoint =\"facebook/esm2_t6_8M_UR50D\"\n",
    "  model_checkpoint =  \"facebook/esm2_t12_35M_UR50D\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4653,
     "status": "ok",
     "timestamp": 1706644670770,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "Eggiq94CubAw",
    "outputId": "9ab29551-cfb8-47d0-9b6d-ff6457e3ca09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>virus</th>\n",
       "      <th>Length</th>\n",
       "      <th>Cluster name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MADFLKGLPVYNKSNFSRFHADSVCKASNRRPSVYLPTREYPSEQI...</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>Cluster: DET1- and DDB1-associated protein 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MPSTLQVLAKKVLALEHKENDHISREYYYHILKCCGLWWHEAPIIL...</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "      <td>Cluster: Protein MGF 360-19R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MASSAELDFNLQALLEQLSQDELSKFKSLIRTISLGKELQTVPQTE...</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>Cluster: Pyrin domain-containing protein 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAAWGKKHAGKDPVRDECEERNRFTETREEDVTDEHGEREPFAETD...</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>Cluster: Protein FAM9B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASDSPARSLDEIDLSALRDPAGIFELVELVGNGTYGQVYKGRHVK...</td>\n",
       "      <td>0</td>\n",
       "      <td>1360</td>\n",
       "      <td>Cluster: TRAF2 and NCK-interacting protein kinase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20335</th>\n",
       "      <td>MDPDKQDALNSIENSIYRTAFKLQSVQTLCQLDLIDSSLIQQVLLR...</td>\n",
       "      <td>0</td>\n",
       "      <td>578</td>\n",
       "      <td>Cluster: Dystrotelin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20336</th>\n",
       "      <td>MLCPWRTANLGLLLILTIFLVAEAEGAAQPNNSLMLQTSKENHALA...</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>Cluster: Cell surface glycoprotein CD200 recep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20337</th>\n",
       "      <td>MCLRFFSPVPGSTSSATNVTMVVSAGPWSSEKAEMNILEINEKLRP...</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "      <td>Cluster: Putative neuroblastoma breakpoint fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20338</th>\n",
       "      <td>MASHAGQQHAPAFGQAARASGPTDGRAASRPSHRQGASEARGDPEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>376</td>\n",
       "      <td>Cluster: Thymidine kinase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20339</th>\n",
       "      <td>MSASSLLEQRPKGQGNKVQNGSVHQKDGLNDDDFEPYLSPQARPNN...</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "      <td>Cluster: YTH domain-containing family protein 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20340 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sequence  virus  Length  \\\n",
       "0      MADFLKGLPVYNKSNFSRFHADSVCKASNRRPSVYLPTREYPSEQI...      0     102   \n",
       "1      MPSTLQVLAKKVLALEHKENDHISREYYYHILKCCGLWWHEAPIIL...      1     362   \n",
       "2      MASSAELDFNLQALLEQLSQDELSKFKSLIRTISLGKELQTVPQTE...      0      97   \n",
       "3      MAAWGKKHAGKDPVRDECEERNRFTETREEDVTDEHGEREPFAETD...      0     186   \n",
       "4      MASDSPARSLDEIDLSALRDPAGIFELVELVGNGTYGQVYKGRHVK...      0    1360   \n",
       "...                                                  ...    ...     ...   \n",
       "20335  MDPDKQDALNSIENSIYRTAFKLQSVQTLCQLDLIDSSLIQQVLLR...      0     578   \n",
       "20336  MLCPWRTANLGLLLILTIFLVAEAEGAAQPNNSLMLQTSKENHALA...      0     348   \n",
       "20337  MCLRFFSPVPGSTSSATNVTMVVSAGPWSSEKAEMNILEINEKLRP...      0     421   \n",
       "20338  MASHAGQQHAPAFGQAARASGPTDGRAASRPSHRQGASEARGDPEL...      1     376   \n",
       "20339  MSASSLLEQRPKGQGNKVQNGSVHQKDGLNDDDFEPYLSPQARPNN...      0     579   \n",
       "\n",
       "                                            Cluster name  \n",
       "0           Cluster: DET1- and DDB1-associated protein 1  \n",
       "1                           Cluster: Protein MGF 360-19R  \n",
       "2             Cluster: Pyrin domain-containing protein 2  \n",
       "3                                 Cluster: Protein FAM9B  \n",
       "4      Cluster: TRAF2 and NCK-interacting protein kinase  \n",
       "...                                                  ...  \n",
       "20335                               Cluster: Dystrotelin  \n",
       "20336  Cluster: Cell surface glycoprotein CD200 recep...  \n",
       "20337  Cluster: Putative neuroblastoma breakpoint fam...  \n",
       "20338                          Cluster: Thymidine kinase  \n",
       "20339    Cluster: YTH domain-containing family protein 2  \n",
       "\n",
       "[20340 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_parquet(DATA_PATH) # numpy to pandas\n",
    "df = pd.read_csv(DATA_PATH,usecols=[\"Sequence\",\"virus\",\"Length\",\"Cluster name\"])\n",
    "df_test = pd.read_csv(TEST_DATA_PATH,usecols=[\"Sequence\",\"virus\",\"Length\",\t\"Cluster name\"])\n",
    " ## lengths of all the seqs\n",
    "\n",
    "if FAST_RUN:\n",
    "#   # df.loc[df[\"Length\"]>100]\n",
    "    df = df.sample(frac=0.1,random_state=4)\n",
    "    df_test = df_test.sample(frac=0.35,random_state=4)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1706644670770,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "fkeYBgfafVoy",
    "outputId": "e8f72139-fcad-41d6-f9df-7fb73571df63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14668.0</td>\n",
       "      <td>473.16</td>\n",
       "      <td>308.52</td>\n",
       "      <td>11.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>1533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5672.0</td>\n",
       "      <td>380.31</td>\n",
       "      <td>298.35</td>\n",
       "      <td>11.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>1520.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count    mean     std   min    25%    50%    75%     max\n",
       "virus                                                            \n",
       "0      14668.0  473.16  308.52  11.0  244.0  398.0  623.0  1533.0\n",
       "1       5672.0  380.31  298.35  11.0  151.0  297.0  514.0  1520.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"virus\"])[\"Length\"].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1706644670770,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "rm2Ms4BmQ4wn",
    "outputId": "a8edf73e-0541-43dd-8537-10b64de09661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean         0.28\n",
      "sum       5672.00\n",
      "count    20340.00\n",
      "Name: virus, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    20340.0\n",
       "mean       447.0\n",
       "std        309.0\n",
       "min         11.0\n",
       "25%        213.0\n",
       "50%        372.0\n",
       "75%        592.0\n",
       "max       1533.0\n",
       "Name: Length, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"virus\"].agg([\"mean\",\"sum\",\"count\"]).round(2))\n",
    "df[\"Length\"].describe().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1706644670770,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "aNDVeR2vQ9YZ",
    "outputId": "7e2d49e5-80a9-4757-a508-3c0374ce038f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4777.0\n",
       "mean      444.3\n",
       "std       304.5\n",
       "min        18.0\n",
       "25%       212.0\n",
       "50%       369.0\n",
       "75%       589.0\n",
       "max      1534.0\n",
       "Name: Length, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Length\"].describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1706644670770,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "F8VNnHUwRQRm",
    "outputId": "c5502a31-ec5d-417d-fb9e-87e1de7d358d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    20340.0\n",
      "mean       447.3\n",
      "std        308.5\n",
      "min         11.0\n",
      "25%        213.0\n",
      "50%        372.0\n",
      "75%        592.2\n",
      "max       1533.0\n",
      "Name: Length, dtype: float64\n",
      "mean         0.28\n",
      "sum       5672.00\n",
      "count    20340.00\n",
      "Name: virus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# df = df.loc[df[\"Length\"]<=2*MAX_LEN].reset_index(drop=True)\n",
    "# df_test = df_test.loc[df_test[\"Length\"]<=2*MAX_LEN].reset_index(drop=True)\n",
    "\n",
    "print(df[\"Length\"].describe().round(1))\n",
    "print(df[\"virus\"].agg([\"mean\",\"sum\",\"count\"]).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PcMwJBkUov07"
   },
   "outputs": [],
   "source": [
    "# ## metadata about all sequences, can be used to identify and to define targets/labels\n",
    "# df_meta = pd.read_excel(METADATA_PATH).dropna(how=\"all\",axis=1)\n",
    "# df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSXy_OzjhIB7"
   },
   "source": [
    "### example pretrained fb/torch:\n",
    "* https://github.com/facebookresearch/esm#getting-started-with-this-repo-\n",
    "\n",
    "* Transformers + trainer example : (mlm case): https://github.com/facebookresearch/esm/discussions/556\n",
    "* keras models supported / via HF?\n",
    "  * https://huggingface.co/docs/transformers/model_doc/esm#transformers.EsmForSequenceClassification.forward.example\n",
    "\n",
    "\n",
    "  TF finetuning example (sequence evel?):\n",
    "  https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb#scrollTo=4b26b828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CDdMQ98rii9t"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AdamWeightDecay\n",
    "from tensorflow.keras.optimizers import Adafactor, Adam # more memory effecient than adamWD\n",
    "import tensorflow\n",
    "# from tensorflow.keras.metrics.AUC()\n",
    "# from transformers import AutoTokenizer #DataCollatorForLanguageModeling,\n",
    "## https://huggingface.co/docs/transformers/model_doc/esm#transformers.EsmForSequenceClassification.forward.example\n",
    "from transformers import AutoTokenizer, EsmForSequenceClassification, Trainer\n",
    "from transformers import TFAutoModelForTokenClassification, TFAutoModelForSequenceClassification ,TFEsmForSequenceClassification\n",
    "\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tcssXXfaVYns"
   },
   "outputs": [],
   "source": [
    "ID2LABEL = {\n",
    "    0: \"Human\",\n",
    "    1: \"Virus\"\n",
    "}\n",
    "LABEL2ID = {v: k for k, v in ID2LABEL.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rR9-cKgPjzW2"
   },
   "outputs": [],
   "source": [
    "train_sequences = df[\"Sequence\"].tolist()\n",
    "train_labels = df[\"virus\"].tolist()\n",
    "train_groups = df[\"Cluster name\"].tolist()\n",
    "\n",
    "# train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)#,stratify=labels)\n",
    "\n",
    "test_sequences = df_test[\"Sequence\"].tolist()\n",
    "test_labels = df_test[\"virus\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install bitsandbytes peft -U\n",
    " \n",
    "# !pip install bitsandbytes transformers peft --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3984,
     "status": "ok",
     "timestamp": 1706644674751,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "k_KUug1Lh5bH",
    "outputId": "14e7d50d-cdfe-4965-9f83-704a4a821e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num labels: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EsmForSequenceClassification(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 640, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1026, 640, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-29): 30 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear4bit(in_features=640, out_features=640, bias=True)\n",
       "              (key): Linear4bit(in_features=640, out_features=640, bias=True)\n",
       "              (value): Linear4bit(in_features=640, out_features=640, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear4bit(in_features=640, out_features=640, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear4bit(in_features=640, out_features=2560, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear4bit(in_features=2560, out_features=640, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear4bit(in_features=600, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (classifier): EsmClassificationHead(\n",
       "    (dense): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=640, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##https://huggingface.co/docs/peft/main/en/developer_guides/quantization\n",
    "## lotfQ config - for this, do not initialize as quantized!\n",
    "# from peft import LoftQConfig, LoraConfig, get_peft_model\n",
    "# loftq_config = LoftQConfig(loftq_bits=4)\n",
    "\n",
    "## https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
    "# compute_dtype = getattr(torch, \"float16\")\n",
    "compute_dtype = getattr(torch, \"bfloat16\")\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True, # disable to train ok;\n",
    "  # load_in_8bit=True, # alt\n",
    "  bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "    # bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    llm_int8_has_fp16_weight =True,\n",
    "    llm_int8_threshold = 5.1,\n",
    "   bnb_4bit_compute_dtype=compute_dtype #torch.bfloat16\n",
    "    ,llm_int8_skip_modules=['classifier',\"EsmClassificationHead\"] # was enabled? \n",
    ")\n",
    "\n",
    "# ### https://huggingface.co/blog/AmelieSchreiber/esm2-ptm\n",
    "# nf4_config = BitsAndBytesConfig(\n",
    "#     # load_in_4bit=True,\n",
    "#     # bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "#     # bnb_4bit_compute_dtype = torch.float16#\"float16\"\n",
    "# )\n",
    "\n",
    "#########################\n",
    "\n",
    "# Load ESM-2 model\n",
    "## smallest: esm2_t6_8M_UR50D\n",
    "## 2d smallest\n",
    "## large: esm2_t33_650M_UR50D\n",
    "\n",
    " # ElnaggarLab/ankh-base\n",
    " ### https://github.com/agemagician/Ankh/blob/main/examples/binary_classification_solubility_task.ipynb - different model?\n",
    " #  https://github.com/agemagician/Ankh#models   - 450M model size # model_checkpoint =   \"ElnaggarLab/ankh-base\"\n",
    "\n",
    "model_max_len = min(1024,MAX_LEN) # 800\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,\n",
    "                                          padding= False#True # orig\n",
    "#                                           padding= True# alt\n",
    "                                          ,truncation=True,max_length=model_max_len)\n",
    "\n",
    "num_labels = max(train_labels + test_labels) + 1  # Add 1 since 0 can be a label\n",
    "print(\"Num labels:\", num_labels)\n",
    "##ORIG:\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels,problem_type=\"single_label_classification\") # worked, orig\n",
    "\n",
    "## try this now, alt:\n",
    "# model = EsmForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "# model = TFEsmForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels,problem_type=\"single_label_classification\")\n",
    "\n",
    "## https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb#scrollTo=fc164b49 # uses trainer\n",
    "##\n",
    "\n",
    "# model = AutoModelForSequenceClassification. # orig\n",
    "# model = EsmForSequenceClassification.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, \n",
    "                                                           problem_type=\"single_label_classification\", # was enabled\n",
    "                                                           # load_in_4bit=True, # disable to train ok\n",
    "                                                            quantization_config=nf4_config,\n",
    "                                                          #  load_in_8bit=True,  torch_dtype=torch.float32, # try this - new\n",
    "                                                           # device_map= \"cuda:0\",#\"auto\",\n",
    "                                                           device_map=\"auto\",\n",
    "                                                          num_labels=len(ID2LABEL), id2label=ID2LABEL, label2id=LABEL2ID,\n",
    "                                                            # trust_remote_code=True\n",
    "                                                           # , from_tf=True,\n",
    "                                                           # force_download =True,\n",
    "                                                          )\n",
    "\n",
    "# last_layer_num = model.num_layers ## 33 for esm2_t33_650M_UR50D\n",
    "# print(last_layer_num )\n",
    "model.train()\n",
    "# model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1706644674751,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "i8amY00Q3HC3",
    "outputId": "9920c745-cdfc-445b-f9a5-39e45a147a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EsmForSequenceClassification(\n",
      "  (esm): EsmModel(\n",
      "    (embeddings): EsmEmbeddings(\n",
      "      (word_embeddings): Embedding(33, 640, padding_idx=1)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (position_embeddings): Embedding(1026, 640, padding_idx=1)\n",
      "    )\n",
      "    (encoder): EsmEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-29): 30 x EsmLayer(\n",
      "          (attention): EsmAttention(\n",
      "            (self): EsmSelfAttention(\n",
      "              (query): Linear4bit(in_features=640, out_features=640, bias=True)\n",
      "              (key): Linear4bit(in_features=640, out_features=640, bias=True)\n",
      "              (value): Linear4bit(in_features=640, out_features=640, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (rotary_embeddings): RotaryEmbedding()\n",
      "            )\n",
      "            (output): EsmSelfOutput(\n",
      "              (dense): Linear4bit(in_features=640, out_features=640, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (intermediate): EsmIntermediate(\n",
      "            (dense): Linear4bit(in_features=640, out_features=2560, bias=True)\n",
      "          )\n",
      "          (output): EsmOutput(\n",
      "            (dense): Linear4bit(in_features=2560, out_features=640, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (contact_head): EsmContactPredictionHead(\n",
      "      (regression): Linear4bit(in_features=600, out_features=1, bias=True)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (classifier): EsmClassificationHead(\n",
      "    (dense): Linear(in_features=640, out_features=640, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (out_proj): Linear(in_features=640, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "# model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False) # prepares the whole model for kbit training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True) # prepares the whole model for kbit training\n",
    "print(model)\n",
    "# #### model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## https://github.com/huggingface/transformers/issues/27702\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     # # Freeze all parameters\n",
    "#     if param.dtype in [torch.float16, torch.float32, torch.float64]:\n",
    "#     #     param.requires_grad = False\n",
    "\n",
    "#         # Unfreeze the last two layers in 'layers' and 'score'\n",
    "#         # if name.startswith('model.layers') and (int(name.split('.')[2]) >= 30):\n",
    "#         #     param.requires_grad = True\n",
    "#         # elif name.startswith('score'):\n",
    "#         #     param.requires_grad = True\n",
    "#         if name.startswith('class'):\n",
    "#             print(name,param.requires_grad)\n",
    "#             param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['esm.encoder.layer.0.attention.self.query', 'esm.encoder.layer.0.attention.self.key', 'esm.encoder.layer.0.attention.self.value', 'esm.encoder.layer.0.attention.output.dense', 'esm.encoder.layer.0.intermediate.dense', 'esm.encoder.layer.0.output.dense', 'esm.encoder.layer.1.attention.self.query', 'esm.encoder.layer.1.attention.self.key', 'esm.encoder.layer.1.attention.self.value', 'esm.encoder.layer.1.attention.output.dense', 'esm.encoder.layer.1.intermediate.dense', 'esm.encoder.layer.1.output.dense', 'esm.encoder.layer.2.attention.self.query', 'esm.encoder.layer.2.attention.self.key', 'esm.encoder.layer.2.attention.self.value', 'esm.encoder.layer.2.attention.output.dense', 'esm.encoder.layer.2.intermediate.dense', 'esm.encoder.layer.2.output.dense', 'esm.encoder.layer.3.attention.self.query', 'esm.encoder.layer.3.attention.self.key', 'esm.encoder.layer.3.attention.self.value', 'esm.encoder.layer.3.attention.output.dense', 'esm.encoder.layer.3.intermediate.dense', 'esm.encoder.layer.3.output.dense', 'esm.encoder.layer.4.attention.self.query', 'esm.encoder.layer.4.attention.self.key', 'esm.encoder.layer.4.attention.self.value', 'esm.encoder.layer.4.attention.output.dense', 'esm.encoder.layer.4.intermediate.dense', 'esm.encoder.layer.4.output.dense', 'esm.encoder.layer.5.attention.self.query', 'esm.encoder.layer.5.attention.self.key', 'esm.encoder.layer.5.attention.self.value', 'esm.encoder.layer.5.attention.output.dense', 'esm.encoder.layer.5.intermediate.dense', 'esm.encoder.layer.5.output.dense', 'esm.encoder.layer.6.attention.self.query', 'esm.encoder.layer.6.attention.self.key', 'esm.encoder.layer.6.attention.self.value', 'esm.encoder.layer.6.attention.output.dense', 'esm.encoder.layer.6.intermediate.dense', 'esm.encoder.layer.6.output.dense', 'esm.encoder.layer.7.attention.self.query', 'esm.encoder.layer.7.attention.self.key', 'esm.encoder.layer.7.attention.self.value', 'esm.encoder.layer.7.attention.output.dense', 'esm.encoder.layer.7.intermediate.dense', 'esm.encoder.layer.7.output.dense', 'esm.encoder.layer.8.attention.self.query', 'esm.encoder.layer.8.attention.self.key', 'esm.encoder.layer.8.attention.self.value', 'esm.encoder.layer.8.attention.output.dense', 'esm.encoder.layer.8.intermediate.dense', 'esm.encoder.layer.8.output.dense', 'esm.encoder.layer.9.attention.self.query', 'esm.encoder.layer.9.attention.self.key', 'esm.encoder.layer.9.attention.self.value', 'esm.encoder.layer.9.attention.output.dense', 'esm.encoder.layer.9.intermediate.dense', 'esm.encoder.layer.9.output.dense', 'esm.encoder.layer.10.attention.self.query', 'esm.encoder.layer.10.attention.self.key', 'esm.encoder.layer.10.attention.self.value', 'esm.encoder.layer.10.attention.output.dense', 'esm.encoder.layer.10.intermediate.dense', 'esm.encoder.layer.10.output.dense', 'esm.encoder.layer.11.attention.self.query', 'esm.encoder.layer.11.attention.self.key', 'esm.encoder.layer.11.attention.self.value', 'esm.encoder.layer.11.attention.output.dense', 'esm.encoder.layer.11.intermediate.dense', 'esm.encoder.layer.11.output.dense', 'esm.encoder.layer.12.attention.self.query', 'esm.encoder.layer.12.attention.self.key', 'esm.encoder.layer.12.attention.self.value', 'esm.encoder.layer.12.attention.output.dense', 'esm.encoder.layer.12.intermediate.dense', 'esm.encoder.layer.12.output.dense', 'esm.encoder.layer.13.attention.self.query', 'esm.encoder.layer.13.attention.self.key', 'esm.encoder.layer.13.attention.self.value', 'esm.encoder.layer.13.attention.output.dense', 'esm.encoder.layer.13.intermediate.dense', 'esm.encoder.layer.13.output.dense', 'esm.encoder.layer.14.attention.self.query', 'esm.encoder.layer.14.attention.self.key', 'esm.encoder.layer.14.attention.self.value', 'esm.encoder.layer.14.attention.output.dense', 'esm.encoder.layer.14.intermediate.dense', 'esm.encoder.layer.14.output.dense', 'esm.encoder.layer.15.attention.self.query', 'esm.encoder.layer.15.attention.self.key', 'esm.encoder.layer.15.attention.self.value', 'esm.encoder.layer.15.attention.output.dense', 'esm.encoder.layer.15.intermediate.dense', 'esm.encoder.layer.15.output.dense', 'esm.encoder.layer.16.attention.self.query', 'esm.encoder.layer.16.attention.self.key', 'esm.encoder.layer.16.attention.self.value', 'esm.encoder.layer.16.attention.output.dense', 'esm.encoder.layer.16.intermediate.dense', 'esm.encoder.layer.16.output.dense', 'esm.encoder.layer.17.attention.self.query', 'esm.encoder.layer.17.attention.self.key', 'esm.encoder.layer.17.attention.self.value', 'esm.encoder.layer.17.attention.output.dense', 'esm.encoder.layer.17.intermediate.dense', 'esm.encoder.layer.17.output.dense', 'esm.encoder.layer.18.attention.self.query', 'esm.encoder.layer.18.attention.self.key', 'esm.encoder.layer.18.attention.self.value', 'esm.encoder.layer.18.attention.output.dense', 'esm.encoder.layer.18.intermediate.dense', 'esm.encoder.layer.18.output.dense', 'esm.encoder.layer.19.attention.self.query', 'esm.encoder.layer.19.attention.self.key', 'esm.encoder.layer.19.attention.self.value', 'esm.encoder.layer.19.attention.output.dense', 'esm.encoder.layer.19.intermediate.dense', 'esm.encoder.layer.19.output.dense', 'esm.encoder.layer.20.attention.self.query', 'esm.encoder.layer.20.attention.self.key', 'esm.encoder.layer.20.attention.self.value', 'esm.encoder.layer.20.attention.output.dense', 'esm.encoder.layer.20.intermediate.dense', 'esm.encoder.layer.20.output.dense', 'esm.encoder.layer.21.attention.self.query', 'esm.encoder.layer.21.attention.self.key', 'esm.encoder.layer.21.attention.self.value', 'esm.encoder.layer.21.attention.output.dense', 'esm.encoder.layer.21.intermediate.dense', 'esm.encoder.layer.21.output.dense', 'esm.encoder.layer.22.attention.self.query', 'esm.encoder.layer.22.attention.self.key', 'esm.encoder.layer.22.attention.self.value', 'esm.encoder.layer.22.attention.output.dense', 'esm.encoder.layer.22.intermediate.dense', 'esm.encoder.layer.22.output.dense', 'esm.encoder.layer.23.attention.self.query', 'esm.encoder.layer.23.attention.self.key', 'esm.encoder.layer.23.attention.self.value', 'esm.encoder.layer.23.attention.output.dense', 'esm.encoder.layer.23.intermediate.dense', 'esm.encoder.layer.23.output.dense', 'esm.encoder.layer.24.attention.self.query', 'esm.encoder.layer.24.attention.self.key', 'esm.encoder.layer.24.attention.self.value', 'esm.encoder.layer.24.attention.output.dense', 'esm.encoder.layer.24.intermediate.dense', 'esm.encoder.layer.24.output.dense', 'esm.encoder.layer.25.attention.self.query', 'esm.encoder.layer.25.attention.self.key', 'esm.encoder.layer.25.attention.self.value', 'esm.encoder.layer.25.attention.output.dense', 'esm.encoder.layer.25.intermediate.dense', 'esm.encoder.layer.25.output.dense', 'esm.encoder.layer.26.attention.self.query', 'esm.encoder.layer.26.attention.self.key', 'esm.encoder.layer.26.attention.self.value', 'esm.encoder.layer.26.attention.output.dense', 'esm.encoder.layer.26.intermediate.dense', 'esm.encoder.layer.26.output.dense', 'esm.encoder.layer.27.attention.self.query', 'esm.encoder.layer.27.attention.self.key', 'esm.encoder.layer.27.attention.self.value', 'esm.encoder.layer.27.attention.output.dense', 'esm.encoder.layer.27.intermediate.dense', 'esm.encoder.layer.27.output.dense', 'esm.encoder.layer.28.attention.self.query', 'esm.encoder.layer.28.attention.self.key', 'esm.encoder.layer.28.attention.self.value', 'esm.encoder.layer.28.attention.output.dense', 'esm.encoder.layer.28.intermediate.dense', 'esm.encoder.layer.28.output.dense', 'esm.encoder.layer.29.attention.self.query', 'esm.encoder.layer.29.attention.self.key', 'esm.encoder.layer.29.attention.self.value', 'esm.encoder.layer.29.attention.output.dense', 'esm.encoder.layer.29.intermediate.dense', 'esm.encoder.layer.29.output.dense', 'esm.contact_head.regression', 'classifier.dense', 'classifier.out_proj']\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "target_modules_allin = [name for name, layer in model.named_modules() if isinstance(layer, nn.Linear)]\n",
    "print(target_modules_allin)\n",
    "\n",
    "modules_list = [\n",
    "            \"position_embeddings\", # alt new\n",
    "            \"query\",\n",
    "            \"key\",\n",
    "            \"value\",\n",
    "            \"EsmSelfOutput.dense\",\n",
    "            \"EsmIntermediate.dense\",\n",
    "            \"EsmOutput.dense\",\n",
    "            \"EsmContactPredictionHead.regression\",\n",
    "            # \"classifier\",\n",
    "            \"EsmClassificationHead.dense\",\n",
    "             \"EsmClassificationHead.out_proj\",\n",
    "            ## try adding? :\n",
    "            \"classifier.dense\", \"classifier.out_proj\", # new\n",
    "#             'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight' # was used\n",
    "        ]\n",
    "\n",
    "target_modules=[\n",
    "            \"query\",\n",
    "            \"key\",\n",
    "            \"value\",\n",
    "            \"EsmSelfOutput.dense\",\n",
    "            \"EsmIntermediate.dense\",\n",
    "            \"EsmOutput.dense\",\n",
    "            # \"EsmContactPredictionHead.regression\",\n",
    "            # \"classifier\"\n",
    "        ],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['value', 'regression', 'dense', 'query', 'key']\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "def find_all_linear_names(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, bnb.nn.Linear4bit):\n",
    "            names = name.split(\".\")\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if \"lm_head\" in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove(\"lm_head\")\n",
    "    return list(lora_module_names)\n",
    "\n",
    "\n",
    "my_lin_layers = find_all_linear_names(model)\n",
    "print(my_lin_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"After we wrap our base model model with PeftModel along with the config, we get a new model where only the LoRA parameters are trainable (so-called “update matrices”) while the pre-trained parameters are kept frozen. These include the parameters of the randomly initialized classifier parameters too. This is NOT we want when fine-tuning the base model on our custom dataset. To ensure that the classifier parameters are also trained, we specify modules_to_save. This also ensures that these modules are serialized alongside the LoRA trainable parameters when using utilities like save_pretrained() and push_to_hub().\n",
    "\n",
    "In addition to specifying the target_modules within LoraConfig, we also need to specify the modules_to_save. When we wrap our base model with PeftModel and pass the configuration, we obtain a new model in which only the LoRA parameters are trainable, while the pre-trained parameters and the randomly initialized classifier parameters are kept frozen. However, we do want to train the classifier parameters. By specifying the modules_to_save argument, we ensure that the classifier parameters are also trainable, and they will be serialized alongside the LoRA trainable parameters when we use utility functions like save_pretrained() and push_to_hub().\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `task_type= \"SEQ_CLS\"` - breaks - RuntimeError: only Tensors of floating point dtype can require gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 1446,
     "status": "ok",
     "timestamp": 1706644676196,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "us1e8ZABC-Ux",
    "outputId": "eca9e5b0-9d94-46a2-eee7-f140620f5cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,196,506 || all params: 152,008,645 || trainable%: 2.10284487438198\n"
     ]
    }
   ],
   "source": [
    "## https://huggingface.co/blog/AmelieSchreiber/esmbind\n",
    "# https://huggingface.co/docs/peft/task_guides/token-classification-lora\n",
    "### target modules?? https://discuss.huggingface.co/t/esm-2-qlora-gradient-checkpointing-not-compatible/53505/2\n",
    "## could also set to all linear? \n",
    "\n",
    "### https://huggingface.co/docs/peft/task_guides/semantic_segmentation_lora#wrap-the-base-model-as-a-peftmodel-for-lora-training\n",
    "\n",
    "peft_config = LoraConfig(base_model_name_or_path=model_checkpoint,\n",
    "#                         init_lora_weights=\"loftq\", loftq_config=loftq_config,\n",
    "    task_type= \"SEQ_CLS\",#TaskType.SEQ_CLS, ## disabling helps?? (then get \"ValueError: Attempting to unscale FP16 gradients.\")\n",
    "    inference_mode=False, r= 2 if FAST_RUN else 8, #16,\n",
    "    lora_alpha=8,\n",
    "    # lora_dropout=0.1,\n",
    "    use_rslora = True,\n",
    "    # bias= \"none\",#\"lora_only\",#\"none\",#\"all\",\n",
    "    # bias=\"all\", #\"lora_only\",\n",
    "    bias=\"lora_only\",\n",
    "    # target_modules=my_lin_layers,\n",
    "    #                      [\n",
    "    #     \"query\", \"key\", \"value\",\n",
    "    #     \"dense\",\n",
    "    # # \"out_proj\"\n",
    "    # ]\n",
    "    #                 \"EsmSelfOutput.dense\",\n",
    "    #         \"EsmIntermediate.dense\",\n",
    "    #         \"EsmOutput.dense\",\n",
    "    #                 # \"word_embeddings\",\n",
    "    #                 # \"EsmClassificationHead.dense\", ## not sure if works/changes anything\n",
    "    #                 # \"out_proj\",\n",
    "    #                 # \"classifier\" # fails\n",
    "    #                 ],\n",
    "        # target_modules=  target_modules#\"all-linear\"#modules_list,\n",
    "           target_modules=  \"all-linear\"\n",
    "                     # target_modules=     target_modules_allin\n",
    "                         \n",
    "    # # ### https://www.kaggle.com/code/andregrbnr/protein-sequence-classification\n",
    "     # ,modules_to_save= # \"all-linear\",\n",
    "      # ,modules_to_save=  [ 'classifier.dense', 'classifier.out_proj'],\n",
    "#                       # \"classifier\",\n",
    "         # ,modules_to_save= [\"EsmClassificationHead\"]\n",
    "      \n",
    "# #          \"pooler\",\n",
    "# # # #                      'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight'\n",
    "                     # ]\n",
    "    ## 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight'\n",
    "    # ,modules_to_save=[\"classifier\"]\n",
    "                         # ,modules_to_save=[ 'classifier.dense', 'classifier.out_proj']\n",
    ")\n",
    "\n",
    "get_peft_model(model, peft_config)\n",
    "\n",
    "# model = get_peft_model(model, peft_config,mixed=True) # mixed prevents peft save, but othewise, 8bit error?\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): EsmForSequenceClassification(\n",
      "      (esm): EsmModel(\n",
      "        (embeddings): EsmEmbeddings(\n",
      "          (word_embeddings): Embedding(33, 640, padding_idx=1)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (position_embeddings): Embedding(1026, 640, padding_idx=1)\n",
      "        )\n",
      "        (encoder): EsmEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0-29): 30 x EsmLayer(\n",
      "              (attention): EsmAttention(\n",
      "                (self): EsmSelfAttention(\n",
      "                  (query): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=640, out_features=640, bias=True)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Identity()\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=640, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=640, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (key): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=640, out_features=640, bias=True)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Identity()\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=640, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=640, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (value): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=640, out_features=640, bias=True)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Identity()\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=640, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=640, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                  (rotary_embeddings): RotaryEmbedding()\n",
      "                )\n",
      "                (output): EsmSelfOutput(\n",
      "                  (dense): lora.Linear4bit(\n",
      "                    (base_layer): Linear4bit(in_features=640, out_features=640, bias=True)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Identity()\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=640, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=640, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "              (intermediate): EsmIntermediate(\n",
      "                (dense): lora.Linear4bit(\n",
      "                  (base_layer): Linear4bit(in_features=640, out_features=2560, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=640, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "              )\n",
      "              (output): EsmOutput(\n",
      "                (dense): lora.Linear4bit(\n",
      "                  (base_layer): Linear4bit(in_features=2560, out_features=640, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=640, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (contact_head): EsmContactPredictionHead(\n",
      "          (regression): lora.Linear4bit(\n",
      "            (base_layer): Linear4bit(in_features=600, out_features=1, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Identity()\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=600, out_features=8, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=8, out_features=1, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "          )\n",
      "          (activation): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (classifier): ModulesToSaveWrapper(\n",
      "        (original_module): EsmClassificationHead(\n",
      "          (dense): lora.Linear(\n",
      "            (base_layer): Linear(in_features=640, out_features=640, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Identity()\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=640, out_features=8, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=8, out_features=640, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (out_proj): lora.Linear(\n",
      "            (base_layer): Linear(in_features=640, out_features=2, bias=True)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Identity()\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=640, out_features=8, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=8, out_features=2, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "          )\n",
      "        )\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): EsmClassificationHead(\n",
      "            (dense): lora.Linear(\n",
      "              (base_layer): Linear(in_features=640, out_features=640, bias=True)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Identity()\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=640, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=640, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (out_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=640, out_features=2, bias=True)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Identity()\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=640, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=2, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "# get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "0Q63xxjeTIDR"
   },
   "outputs": [],
   "source": [
    "# # # ## redo here?\n",
    "# model.gradient_checkpointing_enable()\n",
    "# model = prepare_model_for_kbit_training(model) # prepares the whole model for kbit training\n",
    "# # print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Aw4wKUDNFnBj"
   },
   "outputs": [],
   "source": [
    "## Warning - longer than allowed length - 1024\n",
    "train_tokenized = tokenizer( train_sequences,  truncation=True,max_length=model_max_len,padding=False) # padding=True,\n",
    "test_tokenized = tokenizer(test_sequences,  truncation=True,max_length=model_max_len,padding=False) # padding=True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 4139,
     "status": "ok",
     "timestamp": 1706644730638,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "fQhT9cfOFnED",
    "outputId": "50abafab-4d03-48f7-db6f-6be8a6dfe5a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 20340\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "\n",
    "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "y_4o9iEZFLBZ"
   },
   "outputs": [],
   "source": [
    "# from accelerate import Accelerator\n",
    "# # # Use the accelerator\n",
    "# # ### try disabling? (with qlora)\n",
    "# # accelerator = Accelerator()# trying this\n",
    "# # # # accelerator = Accelerator(mixed_precision=\"fp16\") # fp16 # orig used\n",
    "# model = accelerator.prepare(model)\n",
    "\n",
    "# train_dataset = accelerator.prepare(train_dataset)\n",
    "# test_dataset = accelerator.prepare(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "gBy4OOqJBhha"
   },
   "outputs": [],
   "source": [
    "# print(set(model.hf_device_map.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEcix1ZWfQg-"
   },
   "source": [
    "With 35M model :\n",
    "```\n",
    "Default (1024) max length\n",
    "batch_size=8\n",
    "\n",
    "opt = Adafactor(1e-4)##AdamWeightDecay(1e-4) #default: AdamWeightDecay(2e-5)\n",
    "model.compile(optimizer=opt, metrics=[\"accuracy\"],\n",
    "              loss=\"BinaryCrossentropy\")\n",
    "3813/3813 [==============================] - 2625s 661ms/step - loss: 0.2452 - accuracy: 0.9104 - val_loss: 0.1622 - val_accuracy: 0.9363\n",
    "Epoch 2/3\n",
    "3813/3813 [==============================] - 2518s 661ms/step - loss: 0.1218 - accuracy: 0.9597 - val_loss: 0.1533 - val_accuracy: 0.9463\n",
    "Epoch 3/3\n",
    "3813/3813 [==============================] - 2523s 662ms/step - loss: 0.0730 - accuracy: 0.9799 - val_loss: 0.1978 - val_accuracy: 0.9436\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Q_3tSKYxJJtE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score,roc_auc_score\n",
    "import evaluate\n",
    "\n",
    "from datasets import load_metric\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "    \n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        # 'f1': f1,\n",
    "        # 'precision': precision,\n",
    "        # 'recall': recall,\n",
    "        \"roc_auc\":roc_auc_score(labels,pred.predictions[:,1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1706644733230,
     "user": {
      "displayName": "Dan Ofer",
      "userId": "14537932808605235168"
     },
     "user_tz": -120
    },
    "id": "DUSLawmyM_GS",
    "outputId": "86a59590-af50-4828-e0de-a9da50297f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esm2_t30_150M_UR50D\n"
     ]
    }
   ],
   "source": [
    "# ### AttributeError: 'TFEsmForSequenceClassification' object has no attribute 'to'\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "print(model_name)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-ft-humVir\",\n",
    "    # f\"/content/drive/MyDrive/proteins/New Protein-Virus anom project/t{model_name}-finetuned-humVir\",\n",
    "    per_device_train_batch_size=bch_size,\n",
    "    # per_device_eval_batch_size=int(1.5*bch_size),\n",
    "#     gradient_accumulation_steps= 2, #4,\n",
    "    gradient_checkpointing=True,\n",
    "    # fp16=True,\n",
    "    bf16=True, # needs ampere, not supported ?\n",
    "    tf32=True,\n",
    "        # torch_compile = True,\n",
    "    optim = \"adamw_8bit\", #\"paged_adamw_8bit\", # adamw_bnb_8bit\n",
    "    # optim= \"adamw_bnb_8bit\", #\"paged_adamw_8bit\",\n",
    "    label_names = [\"labels\"],\n",
    "    learning_rate = 5e-4#2e-4 #5e-3,\n",
    "    # lr_scheduler_type=\"cosine\",\n",
    "    ,max_grad_norm = 0.95,\n",
    "#     weight_decay=0.002,\n",
    "    # eval_accumulation_steps = 2#8\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # warmup_ratio=0.02,\n",
    "    save_strategy= \"epoch\",#\"no\",\n",
    "    # output_dir=\".\",\n",
    "     no_cuda=False,\n",
    "     greater_is_better=True,\n",
    "     # save_total_limit=1,\n",
    "  remove_unused_columns=False,\n",
    "    auto_find_batch_size = True, # new , reduces if oom\n",
    "    num_train_epochs=num_epochs,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model= \"roc_auc\",#\"accuracy\",\n",
    "    group_by_length=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  train_dataset=train_dataset,eval_dataset=test_dataset,tokenizer=tokenizer,\n",
    "                  compute_metrics=compute_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "hbj58ofX8umQ",
    "outputId": "a60712d1-b63b-4c6f-a988-d8e8b50a0c77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddofer/anaconda3/envs/hf/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2544' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2544/2544 40:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.122016</td>\n",
       "      <td>0.956458</td>\n",
       "      <td>0.989431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.091597</td>\n",
       "      <td>0.969646</td>\n",
       "      <td>0.993354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddofer/anaconda3/envs/hf/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_MODEL:\n",
    "    result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EyRpkv4OkP0V"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='598' max='598' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [598/598 02:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.09159661084413528,\n",
       " 'eval_accuracy': 0.969646221477915,\n",
       " 'eval_roc_auc': 0.9933538461538461,\n",
       " 'eval_runtime': 134.7247,\n",
       " 'eval_samples_per_second': 35.457,\n",
       " 'eval_steps_per_second': 4.439,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "yifiIXEx_HcR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'small_trained_esm_lora_trainer_model'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DRIVE_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "PmoPkjy9LhCx"
   },
   "outputs": [],
   "source": [
    "# print(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "VvTTO8X13jRs"
   },
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:    \n",
    "    if SAVE_MODEL:\n",
    "      # trainer.model.merge_and_unload() # merges the adapter layers into the base model. (vs saving just adapter part?)\n",
    "      if FAST_RUN:\n",
    "        # trainer.save_model(\"/content/drive/MyDrive/proteins/New Protein-Virus anom project/mini_trained_esm_qlora_trainer_model\")\n",
    "        trainer.model.save_pretrained(MODEL_DRIVE_SAVE_PATH) #. PEFT friendly\n",
    "      else:\n",
    "        # trainer.save_model(MODEL_DRIVE_SAVE_PATH)\n",
    "        trainer.model.save_pretrained(MODEL_DRIVE_SAVE_PATH) #. PEFT friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1uMm7Apt1PR7"
   },
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    \n",
    "    try: trainer.model.eval()\n",
    "    except:()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyaiUSi0DP6r"
   },
   "source": [
    "### load model for **comparison**\n",
    "* , untrained model ?\n",
    "*  https://huggingface.co/blog/AmelieSchreiber/esmbind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'facebook/esm2_t30_150M_UR50D'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "6jyS1XD9DPI0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EsmForSequenceClassification(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 640, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1026, 640, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-29): 30 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (key): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (value): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=640, out_features=2560, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=2560, out_features=640, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=600, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (classifier): EsmClassificationHead(\n",
       "    (dense): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=640, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### https://huggingface.co/blog/AmelieSchreiber/esmbind\n",
    "# # Path to the saved LoRA model\n",
    "# model_path = \"AmelieSchreiber/esm2_t12_35M_lora_binding_sites_v2_cp3\"\n",
    "# # ESM2 base model\n",
    "# base_model_path = \"facebook/esm2_t12_35M_UR50D\"\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels,problem_type=\"single_label_classification\")\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "2PwK94icaX_o"
   },
   "outputs": [],
   "source": [
    "if FAST_RUN:\n",
    "  print(Trainer(model=base_model, args=training_args,\n",
    "                  train_dataset=train_dataset,eval_dataset=test_dataset,tokenizer=tokenizer,\n",
    "                  compute_metrics=compute_metrics,).evaluate()) # worse than trained model - OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "u1pYpEezBD2E"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'small_trained_esm_lora_trainer_model'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DRIVE_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "R62G7yFduRiL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading adapter weights from small_trained_esm_lora_trainer_model led to unexpected keys not found in the model:  ['classifier.modules_to_save.dense.lora_A.default.weight', 'classifier.modules_to_save.dense.lora_B.default.weight', 'classifier.modules_to_save.out_proj.lora_A.default.weight', 'classifier.modules_to_save.out_proj.lora_B.default.weight', 'classifier.original_module.dense.lora_A.default.weight', 'classifier.original_module.dense.lora_B.default.weight', 'classifier.original_module.out_proj.lora_A.default.weight', 'classifier.original_module.out_proj.lora_B.default.weight']. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): EsmForSequenceClassification(\n",
       "      (esm): EsmModel(\n",
       "        (embeddings): EsmEmbeddings(\n",
       "          (word_embeddings): Embedding(33, 640, padding_idx=1)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (position_embeddings): Embedding(1026, 640, padding_idx=1)\n",
       "        )\n",
       "        (encoder): EsmEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-29): 30 x EsmLayer(\n",
       "              (attention): EsmAttention(\n",
       "                (self): EsmSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=640, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=640, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=640, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=640, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=640, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=640, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (rotary_embeddings): RotaryEmbedding()\n",
       "                )\n",
       "                (output): EsmSelfOutput(\n",
       "                  (dense): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=640, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=640, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (intermediate): EsmIntermediate(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=640, out_features=2560, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=640, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "              )\n",
       "              (output): EsmOutput(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=640, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=640, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (contact_head): EsmContactPredictionHead(\n",
       "          (regression): lora.Linear(\n",
       "            (base_layer): Linear(in_features=600, out_features=1, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=600, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=1, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): EsmClassificationHead(\n",
       "          (dense): lora.Linear(\n",
       "            (base_layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=640, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=640, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (out_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=640, out_features=2, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Identity()\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=640, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=2, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): EsmClassificationHead(\n",
       "            (dense): lora.Linear(\n",
       "              (base_layer): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=640, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=640, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (out_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=640, out_features=2, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=640, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=2, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### it says it is not loading saved classifier weights?? but trainer pred gives ok results (better than with random model)? \n",
    "from peft import PeftModelForSequenceClassification, get_peft_config\n",
    "if LOAD_TRAINED:\n",
    "    \"\"\"\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels,problem_type=\"single_label_classification\")\n",
    "    \"\"\"\n",
    "#   ### load pretrained, trained model?\n",
    "\n",
    "    # trained_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint,num_labels=num_labels,problem_type=\"single_label_classification\")\n",
    "    # print(\"loading PEFT config\")\n",
    "\n",
    "    # trained_model = PeftModelForSequenceClassification.from_pretrained(trained_model, MODEL_DRIVE_SAVE_PATH,\n",
    "    #                                                                    config=peft_config) # alt\n",
    "    \n",
    "    trained_model = AutoModelForSequenceClassification.from_pretrained(MODEL_DRIVE_SAVE_PATH,\n",
    "                                                                  num_labels=num_labels,problem_type=\"single_label_classification\") \n",
    "    trained_model = PeftModel.from_pretrained(trained_model, MODEL_DRIVE_SAVE_PATH)\n",
    "    ## \n",
    "#     trained_model = prepare_model_for_kbit_training(trained_model, use_gradient_checkpointing=True)\n",
    "    \n",
    "else:\n",
    "    trained_model = trainer.model\n",
    "trained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "6ibDslHLW04H"
   },
   "outputs": [],
   "source": [
    "## check if saved loaded ok?\n",
    "if FAST_RUN:\n",
    "  print(Trainer(model=trained_model, args=training_args,tokenizer=tokenizer,\n",
    "                    train_dataset=train_dataset,eval_dataset=test_dataset,\n",
    "                    compute_metrics=compute_metrics,).evaluate()) ## only ok if better than random init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "97O_ItcTmgh3"
   },
   "outputs": [],
   "source": [
    "if FAST_RUN:\n",
    "  print(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# tok.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=m, tokenizer=tok)\n",
    "\n",
    "# classifier(\"Today was an amazing day\", candidate_labels=[\"negative\", \"positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZqNMJgTM-zb"
   },
   "source": [
    "* Cao - maybe use only RBD domain ,  (+- mutation site?)\n",
    "\n",
    "\n",
    "* Could get WT prediction, and get **delta** of mutant's predicted score vs wt - then examine that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuInD2PVjT_j"
   },
   "source": [
    "* https://huggingface.co/docs/transformers/model_doc/esm#transformers.EsmForSequenceClassification.forward.example\n",
    "\n",
    "\n",
    "* Eval related batch size stuff: https://discuss.huggingface.co/t/batch-size-for-trainer-predict/3374/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "bE5fCdPrJVGH"
   },
   "outputs": [],
   "source": [
    "# CAO_TEST_DATA_PATH = \"/content/drive/MyDrive/proteins/New Protein-Virus anom project/cao_escaper_targets_max.csv\"##\n",
    "# CAO_TEST_DATA_PATH = \"/kaggle/input/humvir-proteins/cao_escaper_targets_max.csv\"\n",
    "CAO_TEST_DATA_PATH = \"cao_escaper_targets_max.csv\"\n",
    "\n",
    "### all data, more redundnat - same seq repeated, can join with our res to save time.\n",
    "# CAO_full_TEST_DATA_PATH = \"/kaggle/input/humvir-proteins/cao_escaper_targets_all.csv\"\n",
    "CAO_full_TEST_DATA_PATH = \"cao_escaper_targets_all.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "WyIXqfCDsN--"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>wildtype</th>\n",
       "      <th>mutation</th>\n",
       "      <th>mut_escape</th>\n",
       "      <th>seq</th>\n",
       "      <th>mut_escape_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34673</th>\n",
       "      <td>489</td>\n",
       "      <td>Y</td>\n",
       "      <td>R</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34674</th>\n",
       "      <td>489</td>\n",
       "      <td>Y</td>\n",
       "      <td>S</td>\n",
       "      <td>0.185581</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34675</th>\n",
       "      <td>489</td>\n",
       "      <td>Y</td>\n",
       "      <td>T</td>\n",
       "      <td>0.088192</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34676</th>\n",
       "      <td>489</td>\n",
       "      <td>Y</td>\n",
       "      <td>V</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34677</th>\n",
       "      <td>489</td>\n",
       "      <td>Y</td>\n",
       "      <td>W</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       site wildtype mutation  mut_escape  \\\n",
       "0       331        N        A    0.000000   \n",
       "1       331        N        C    0.000000   \n",
       "2       331        N        D    0.000000   \n",
       "3       331        N        E    0.000000   \n",
       "4       331        N        F    0.000000   \n",
       "...     ...      ...      ...         ...   \n",
       "34673   489        Y        R    0.001041   \n",
       "34674   489        Y        S    0.185581   \n",
       "34675   489        Y        T    0.088192   \n",
       "34676   489        Y        V    0.014363   \n",
       "34677   489        Y        W    0.000956   \n",
       "\n",
       "                                                     seq  mut_escape_class  \n",
       "0      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 0  \n",
       "1      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 0  \n",
       "2      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 0  \n",
       "3      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 0  \n",
       "4      MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 0  \n",
       "...                                                  ...               ...  \n",
       "34673  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 1  \n",
       "34674  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 1  \n",
       "34675  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 1  \n",
       "34676  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 1  \n",
       "34677  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...                 1  \n",
       "\n",
       "[34678 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cao = pd.read_csv(CAO_TEST_DATA_PATH)\n",
    "# if FAST_RUN:\n",
    "#   df_cao = df_cao.head(100)\n",
    "\n",
    "df_cao_full = pd.read_csv(CAO_full_TEST_DATA_PATH)\n",
    "print(df_cao_full[\"seq\"].nunique())\n",
    "print(df_cao_full[\"seq\"].str.len())\n",
    "display(df_cao_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "w_LiqdXNls_1"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def get_escaper_scores(df:pd.DataFrame,trained_model,base_model,seqColName=\"seq\",truncate_cao=False,\n",
    "                       binary_target_col = None):\n",
    "  if truncate_cao:\n",
    "  ## truncated version +-20:\n",
    "    cao_sequences = df[seqColName].str[300:550].tolist() # ONLY RBD domain\n",
    "    max_len = 550-300\n",
    "  else:\n",
    "    cao_sequences = df[seqColName].tolist()\n",
    "    max_len = df[seqColName].str.len().max()+2\n",
    "\n",
    "  cao_test_seq = tokenizer(cao_sequences,  truncation=True\n",
    "                          ,max_length= min(max_len,1024)#1024\n",
    "                        #  max_length= 700 #600 #model_max_len,\n",
    "                         # ,padding=False#True,\n",
    "                           ,padding=True\n",
    "                           ,return_tensors=\"pt\")\n",
    "\n",
    "  cao_test_seq = Dataset.from_dict(cao_test_seq)\n",
    "  # cao_test_seq = accelerator.prepare(cao_test_seq)\n",
    "    ## get naive models preds - WHY are they similar to trained models ???\n",
    "  # \"\"\"\n",
    "  base_trainer = Trainer(base_model,tokenizer=tokenizer,args=training_args)\n",
    "  raw_pred, _, _ = base_trainer.predict(cao_test_seq)\n",
    "  # predictedLabelOnCompanyData = np.argmax(raw_pred, axis=1)\n",
    "  # df[\"base_pred_vir\"] = raw_pred[:,1]\n",
    "  df[\"base_pred_vir\"] = torch.nn.functional.softmax(torch.tensor(raw_pred), dim=1)[:,1]\n",
    "  # \"\"\"\n",
    "    \n",
    "  ## preds with proper model\n",
    "  trainer = Trainer(model=trained_model,tokenizer=tokenizer,args=training_args) # added here...\n",
    "    ### https://discuss.huggingface.co/t/transform-logits-to-probabilities-doesnt-work/14792\n",
    "  logits, _, _ = trainer.predict(cao_test_seq)\n",
    "\n",
    "  # print(softmax(logits[:,1]))\n",
    "  # df[\"probabilities\"] = softmax(logits[:,1]) #(preds_output[0], axis=1)#probabilities\n",
    "    \n",
    "  # df[\"model_pred_vir\"] =  logits[:,1]\n",
    "  # df[\"model_pred_hum\"] = softmax(logits, axis=0) #softmax(logits[:,0])\n",
    "  # df[\"model_pred_vir\"] =  softmax(logits[:,1])\n",
    "  df[\"model_pred_vir\"] =  torch.nn.functional.softmax(torch.tensor(logits), dim=1)[:,1]\n",
    "  df[\"model_pred_hum\"] =  torch.nn.functional.softmax(torch.tensor(logits), dim=1)[:,0]\n",
    "  # df[\"sum\"] = (df[\"model_pred_hum\"]+df[\"model_pred_vir\"]).round(2) # adds up to 1\n",
    "  df[\"model_pred_hum_delta\"] = df[\"model_pred_hum\"].round(4)\n",
    "\n",
    "  ## subtract WT pred score - to get deltas. WT is most common (as it reoccurs)\n",
    "  mode_score = df[\"model_pred_hum\"].round(4).mode()[0]\n",
    "  df[\"model_pred_hum_delta\"] = df[\"model_pred_hum_delta\"] - mode_score\n",
    "  print(df.describe().round(3))\n",
    "\n",
    "  display(df.select_dtypes([\"number\",\"bool\"]).corr().round(3))\n",
    "\n",
    "  if binary_target_col is not None:\n",
    "    print(\"humVir trained model - human pred delta - ROCAUC:\",roc_auc_score(df[binary_target_col], df[\"model_pred_hum_delta\"]).round(4))\n",
    "    print(\"humVir trained model ROCAUC:\",roc_auc_score(df[binary_target_col], df[\"model_pred_hum\"]).round(4))\n",
    "    print(classification_report(df[binary_target_col],np.argmax(logits, axis=-1)))\n",
    "    print(\"Untrained vir model: ROCAUC\",roc_auc_score(df[binary_target_col], df[\"base_pred_vir\"]).round(4))\n",
    "\n",
    "  return df\n",
    "\n",
    "# get_escaper_scores(df_iedb_vir.sample(16).copy(),trained_model=model,base_model=base_model,seqColName=\"Epitopes - Epitope\",truncate_cao=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Nx94FfFvJtoo"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>wildtype</th>\n",
       "      <th>mutation</th>\n",
       "      <th>mut_escape</th>\n",
       "      <th>mut_escape_class</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>0.112258</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>S</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>V</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>W</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4020 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      site wildtype mutation  mut_escape  mut_escape_class  \\\n",
       "0      331        N        A    0.009428                 1   \n",
       "1      331        N        C    0.000000                 0   \n",
       "2      331        N        D    0.026596                 1   \n",
       "3      331        N        E    0.112258                 1   \n",
       "4      331        N        F    0.012256                 1   \n",
       "...    ...      ...      ...         ...               ...   \n",
       "4015   531        T        S    0.010178                 1   \n",
       "4016   531        T        T    0.000000                 0   \n",
       "4017   531        T        V    0.009521                 1   \n",
       "4018   531        T        W    0.008336                 1   \n",
       "4019   531        T        Y    0.017168                 1   \n",
       "\n",
       "                                                    seq  \n",
       "0     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "1     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "2     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "3     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "4     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "...                                                 ...  \n",
       "4015  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "4016  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "4017  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "4018  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "4019  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "\n",
       "[4020 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_cao[\"seq\"] = df_cao[\"seq\"].str[0:MAX_LEN+100]\n",
    "df_cao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "FxNylFeuKole"
   },
   "outputs": [],
   "source": [
    "# # model.eval()\n",
    "# ## truncated version +-20:\n",
    "# cao_sequences = df_cao[\"seq\"].str[300:550].tolist() # ONLY RBD domain\n",
    "# # cao_sequences = df_cao[\"seq\"].tolist()\n",
    "\n",
    "# ## ALT:\n",
    "# cao_sequences = df_cao[\"seq\"].str[0:550].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ACslPC3Ah8Ey"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          site  mut_escape  mut_escape_class  base_pred_vir  model_pred_vir  \\\n",
      "count  4020.00    4020.000          4020.000       4020.000          4020.0   \n",
      "mean    431.00       0.197             0.528          0.495             1.0   \n",
      "std      58.03       0.335             0.499          0.001             0.0   \n",
      "min     331.00       0.000             0.000          0.491             1.0   \n",
      "25%     381.00       0.000             0.000          0.494             1.0   \n",
      "50%     431.00       0.007             1.000          0.495             1.0   \n",
      "75%     481.00       0.305             1.000          0.496             1.0   \n",
      "max     531.00       3.602             1.000          0.501             1.0   \n",
      "\n",
      "       model_pred_hum  model_pred_hum_delta  \n",
      "count          4020.0                4020.0  \n",
      "mean              0.0                   0.0  \n",
      "std               0.0                   0.0  \n",
      "min               0.0                   0.0  \n",
      "25%               0.0                   0.0  \n",
      "50%               0.0                   0.0  \n",
      "75%               0.0                   0.0  \n",
      "max               0.0                   0.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>mut_escape</th>\n",
       "      <th>mut_escape_class</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mut_escape</th>\n",
       "      <td>0.073</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mut_escape_class</th>\n",
       "      <td>0.093</td>\n",
       "      <td>0.555</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_pred_vir</th>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.035</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_vir</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum</th>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.244</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       site  mut_escape  mut_escape_class  base_pred_vir  \\\n",
       "site                  1.000       0.073             0.093         -0.294   \n",
       "mut_escape            0.073       1.000             0.555          0.002   \n",
       "mut_escape_class      0.093       0.555             1.000          0.035   \n",
       "base_pred_vir        -0.294       0.002             0.035          1.000   \n",
       "model_pred_vir        0.235       0.061             0.043         -0.182   \n",
       "model_pred_hum       -0.235      -0.061            -0.042          0.182   \n",
       "model_pred_hum_delta -0.050      -0.026            -0.046          0.032   \n",
       "\n",
       "                      model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
       "site                           0.235          -0.235                -0.050  \n",
       "mut_escape                     0.061          -0.061                -0.026  \n",
       "mut_escape_class               0.043          -0.042                -0.046  \n",
       "base_pred_vir                 -0.182           0.182                 0.032  \n",
       "model_pred_vir                 1.000          -1.000                -0.244  \n",
       "model_pred_hum                -1.000           1.000                 0.244  \n",
       "model_pred_hum_delta          -0.244           0.244                 1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humVir trained model - human pred delta - ROCAUC: 0.4976\n",
      "humVir trained model ROCAUC: 0.4781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1897\n",
      "           1       0.53      1.00      0.69      2123\n",
      "\n",
      "    accuracy                           0.53      4020\n",
      "   macro avg       0.26      0.50      0.35      4020\n",
      "weighted avg       0.28      0.53      0.37      4020\n",
      "\n",
      "Untrained vir model: ROCAUC 0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddofer/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ddofer/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ddofer/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "df_cao_preds = get_escaper_scores(df_cao.copy(),trained_model=trainer.model,\n",
    "                   base_model=base_model,seqColName=\"seq\",truncate_cao=True,\n",
    "                       binary_target_col = \"mut_escape_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4821+0.5147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "SH0IzxxHkYVv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          site  mut_escape  mut_escape_class  base_pred_vir  model_pred_vir  \\\n",
      "count  4020.00    4020.000          4020.000       4020.000          4020.0   \n",
      "mean    431.00       0.197             0.528          0.495             1.0   \n",
      "std      58.03       0.335             0.499          0.001             0.0   \n",
      "min     331.00       0.000             0.000          0.491             1.0   \n",
      "25%     381.00       0.000             0.000          0.494             1.0   \n",
      "50%     431.00       0.007             1.000          0.495             1.0   \n",
      "75%     481.00       0.305             1.000          0.496             1.0   \n",
      "max     531.00       3.602             1.000          0.501             1.0   \n",
      "\n",
      "       model_pred_hum  model_pred_hum_delta  \n",
      "count          4020.0                4020.0  \n",
      "mean              0.0                   0.0  \n",
      "std               0.0                   0.0  \n",
      "min               0.0                   0.0  \n",
      "25%               0.0                   0.0  \n",
      "50%               0.0                   0.0  \n",
      "75%               0.0                   0.0  \n",
      "max               0.0                   0.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>mut_escape</th>\n",
       "      <th>mut_escape_class</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mut_escape</th>\n",
       "      <td>0.073</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mut_escape_class</th>\n",
       "      <td>0.093</td>\n",
       "      <td>0.555</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_pred_vir</th>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.035</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_vir</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum</th>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.244</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       site  mut_escape  mut_escape_class  base_pred_vir  \\\n",
       "site                  1.000       0.073             0.093         -0.294   \n",
       "mut_escape            0.073       1.000             0.555          0.002   \n",
       "mut_escape_class      0.093       0.555             1.000          0.035   \n",
       "base_pred_vir        -0.294       0.002             0.035          1.000   \n",
       "model_pred_vir        0.235       0.061             0.043         -0.182   \n",
       "model_pred_hum       -0.235      -0.061            -0.042          0.182   \n",
       "model_pred_hum_delta -0.050      -0.026            -0.046          0.032   \n",
       "\n",
       "                      model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
       "site                           0.235          -0.235                -0.050  \n",
       "mut_escape                     0.061          -0.061                -0.026  \n",
       "mut_escape_class               0.043          -0.042                -0.046  \n",
       "base_pred_vir                 -0.182           0.182                 0.032  \n",
       "model_pred_vir                 1.000          -1.000                -0.244  \n",
       "model_pred_hum                -1.000           1.000                 0.244  \n",
       "model_pred_hum_delta          -0.244           0.244                 1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humVir trained model - human pred delta - ROCAUC: 0.4976\n",
      "humVir trained model ROCAUC: 0.4781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1897\n",
      "           1       0.53      1.00      0.69      2123\n",
      "\n",
      "    accuracy                           0.53      4020\n",
      "   macro avg       0.26      0.50      0.35      4020\n",
      "weighted avg       0.28      0.53      0.37      4020\n",
      "\n",
      "Untrained vir model: ROCAUC 0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddofer/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ddofer/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ddofer/anaconda3/envs/hf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>wildtype</th>\n",
       "      <th>mutation</th>\n",
       "      <th>mut_escape</th>\n",
       "      <th>mut_escape_class</th>\n",
       "      <th>seq</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.495930</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.496304</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.495432</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>0.112258</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.495812</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>331</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.495663</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>S</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.495720</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.495187</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>V</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.492699</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>W</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.492916</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>531</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>1</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.493208</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4020 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      site wildtype mutation  mut_escape  mut_escape_class  \\\n",
       "0      331        N        A    0.009428                 1   \n",
       "1      331        N        C    0.000000                 0   \n",
       "2      331        N        D    0.026596                 1   \n",
       "3      331        N        E    0.112258                 1   \n",
       "4      331        N        F    0.012256                 1   \n",
       "...    ...      ...      ...         ...               ...   \n",
       "4015   531        T        S    0.010178                 1   \n",
       "4016   531        T        T    0.000000                 0   \n",
       "4017   531        T        V    0.009521                 1   \n",
       "4018   531        T        W    0.008336                 1   \n",
       "4019   531        T        Y    0.017168                 1   \n",
       "\n",
       "                                                    seq  base_pred_vir  \\\n",
       "0     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.495930   \n",
       "1     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.496304   \n",
       "2     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.495432   \n",
       "3     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.495812   \n",
       "4     MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.495663   \n",
       "...                                                 ...            ...   \n",
       "4015  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.495720   \n",
       "4016  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.495187   \n",
       "4017  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.492699   \n",
       "4018  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.492916   \n",
       "4019  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.493208   \n",
       "\n",
       "      model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
       "0           0.999880        0.000120                   0.0  \n",
       "1           0.999891        0.000109                   0.0  \n",
       "2           0.999888        0.000112                   0.0  \n",
       "3           0.999864        0.000136                   0.0  \n",
       "4           0.999891        0.000109                   0.0  \n",
       "...              ...             ...                   ...  \n",
       "4015        0.999880        0.000120                   0.0  \n",
       "4016        0.999901        0.000099                   0.0  \n",
       "4017        0.999901        0.000099                   0.0  \n",
       "4018        0.999856        0.000144                   0.0  \n",
       "4019        0.999880        0.000120                   0.0  \n",
       "\n",
       "[4020 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## mode without save + load\n",
    "get_escaper_scores(df_cao,trained_model=model, #trainer,\n",
    "                   base_model=base_model,seqColName=\"seq\",truncate_cao=True,\n",
    "                       binary_target_col = \"mut_escape_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "_F4FYloQ4A5R"
   },
   "outputs": [],
   "source": [
    "# df_cao[\"model_pred_vir\"].describe().round(4)\n",
    "# df_cao[\"model_pred_hum\"].value_counts() ## most common (271) value - unmutated score/WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "cTc1aPqhSreR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>mut_escape</th>\n",
       "      <th>mut_escape_class</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mut_escape</th>\n",
       "      <td>0.073</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mut_escape_class</th>\n",
       "      <td>0.093</td>\n",
       "      <td>0.555</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_pred_vir</th>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.035</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_vir</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum</th>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>0.244</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       site  mut_escape  mut_escape_class  base_pred_vir  \\\n",
       "site                  1.000       0.073             0.093         -0.294   \n",
       "mut_escape            0.073       1.000             0.555          0.002   \n",
       "mut_escape_class      0.093       0.555             1.000          0.035   \n",
       "base_pred_vir        -0.294       0.002             0.035          1.000   \n",
       "model_pred_vir        0.235       0.061             0.043         -0.182   \n",
       "model_pred_hum       -0.235      -0.061            -0.042          0.182   \n",
       "model_pred_hum_delta -0.050      -0.026            -0.046          0.032   \n",
       "\n",
       "                      model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
       "site                           0.235          -0.235                -0.050  \n",
       "mut_escape                     0.061          -0.061                -0.026  \n",
       "mut_escape_class               0.043          -0.042                -0.046  \n",
       "base_pred_vir                 -0.182           0.182                 0.032  \n",
       "model_pred_vir                 1.000          -1.000                -0.244  \n",
       "model_pred_hum                -1.000           1.000                 0.244  \n",
       "model_pred_hum_delta          -0.244           0.244                 1.000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cao.select_dtypes([\"number\",\"bool\"]).corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3820"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge preds and plot vs escaper score (across many conditions. partially dedupped by cond + identicals)\n",
    "df_cao_full[\"seq\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34678\n",
      "34478\n"
     ]
    }
   ],
   "source": [
    "print(df_cao_full.shape[0])\n",
    "df_cao_full = df_cao_full[['mut_escape', 'seq', 'mut_escape_class']].drop_duplicates()\n",
    "print(df_cao_full.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3820"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cao_preds[\"seq\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4020"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cao_preds.shape[0]\n",
    "## there are multiple preds of different outputs values for the same identical mutation sequence. ? \n",
    "## we'll take the max ? or plot all? \n",
    "# df_cao_preds.groupby('seq')[['base_pred_vir', 'model_pred_hum', 'model_pred_hum_delta']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mut_escape</th>\n",
       "      <th>seq</th>\n",
       "      <th>mut_escape_class</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495930</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.496304</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495432</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495812</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495663</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34673</th>\n",
       "      <td>0.001041</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494961</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34674</th>\n",
       "      <td>0.185581</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495354</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34675</th>\n",
       "      <td>0.088192</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495150</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34676</th>\n",
       "      <td>0.014363</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495245</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34677</th>\n",
       "      <td>0.000956</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.492653</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34678 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mut_escape                                                seq  \\\n",
       "0        0.000000  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "1        0.000000  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "2        0.000000  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "3        0.000000  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "4        0.000000  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "...           ...                                                ...   \n",
       "34673    0.001041  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "34674    0.185581  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "34675    0.088192  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "34676    0.014363  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "34677    0.000956  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "\n",
       "       mut_escape_class  base_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
       "0                     0       0.495930        0.000120                   0.0  \n",
       "1                     0       0.496304        0.000109                   0.0  \n",
       "2                     0       0.495432        0.000112                   0.0  \n",
       "3                     0       0.495812        0.000136                   0.0  \n",
       "4                     0       0.495663        0.000109                   0.0  \n",
       "...                 ...            ...             ...                   ...  \n",
       "34673                 1       0.494961        0.000106                   0.0  \n",
       "34674                 1       0.495354        0.000106                   0.0  \n",
       "34675                 1       0.495150        0.000082                   0.0  \n",
       "34676                 1       0.495245        0.000082                   0.0  \n",
       "34677                 1       0.492653        0.000106                   0.0  \n",
       "\n",
       "[34678 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## more rows made? \n",
    "# df_cao_full.merge(df_cao_preds.set_index('seq')[['base_pred_vir', 'model_pred_hum', 'model_pred_hum_delta']],on='seq')\n",
    "\n",
    "# df_cao_full_merged = df_cao_full.merge(df_cao_preds.groupby('seq')[['base_pred_vir', 'model_pred_hum', 'model_pred_hum_delta']].max(),on='seq')\n",
    "# alt:\n",
    "df_cao_full_merged = df_cao_full.merge(df_cao_preds.set_index('seq')[['base_pred_vir', 'model_pred_hum', 'model_pred_hum_delta']],on='seq')\n",
    "df_cao_full_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mut_escape</th>\n",
       "      <th>mut_escape_class</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mut_escape</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mut_escape_class</th>\n",
       "      <td>0.210</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_pred_vir</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum</th>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.084</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.117</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mut_escape  mut_escape_class  base_pred_vir  \\\n",
       "mut_escape                 1.000             0.210         -0.012   \n",
       "mut_escape_class           0.210             1.000          0.005   \n",
       "base_pred_vir             -0.012             0.005          1.000   \n",
       "model_pred_hum            -0.018            -0.058          0.084   \n",
       "model_pred_hum_delta      -0.011            -0.034          0.029   \n",
       "\n",
       "                      model_pred_hum  model_pred_hum_delta  \n",
       "mut_escape                    -0.018                -0.011  \n",
       "mut_escape_class              -0.058                -0.034  \n",
       "base_pred_vir                  0.084                 0.029  \n",
       "model_pred_hum                 1.000                 0.117  \n",
       "model_pred_hum_delta           0.117                 1.000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cao_full_merged.corr(numeric_only=True).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mut_escape', 'seq', 'mut_escape_class', 'base_pred_vir',\n",
       "       'model_pred_hum', 'model_pred_hum_delta'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cao_full_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4215/1338866085.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_cao_full_merged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"base_pred_vir\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"model_pred_hum\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"model_pred_hum_delta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cao_full_merged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hf/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11020\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11021\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11022\u001b[0m         \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11024\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pearson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11025\u001b[0m             \u001b[0mcorrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnancorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11026\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spearman\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11027\u001b[0m             \u001b[0mcorrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnancorr_spearman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hf/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1577\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "df_cao_full_merged[[\"base_pred_vir\",\"model_pred_hum\",\"model_pred_hum_delta\"]].corr(df_cao_full_merged,numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "TYo-lBTWvUt2"
   },
   "outputs": [],
   "source": [
    "# print(classification_report(df_cao[\"mut_escape_class\"],np.argmax(logits, axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiO5IxnQj2_D"
   },
   "source": [
    "Viral escape data:\n",
    "\n",
    "```\n",
    "!wget http://cb.csail.mit.edu/cb/viral-mutation/data.tar.gz\n",
    "!tar xvf data.tar.gz\n",
    "```\n",
    "* https://github.com/brianhie/viral-mutation/tree/master/results\n",
    "* wget from : https://colab.research.google.com/github/vanvalenlab/bebi205/blob/master/bebi205/notebooks/sequences-key.ipynb#scrollTo=VN607f41e_qp\n",
    "  * relatively large - 3GB zipped!\n",
    "\n",
    "\n",
    "Example output from them (maybe cov2 seq), with escaper results value:\n",
    "https://github.com/brianhie/viral-mutation/blob/master/examples/example_results.txt\n",
    "\n",
    "* another for flu (1, h3)... https://github.com/brianhie/viral-mutation/blob/master/results/flu/semantics/analyze_semantics_flu_h1_bilstm_512.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-gCOl4rj21r"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "oQqyQiIokI5I"
   },
   "outputs": [],
   "source": [
    "# !wget http://cb.csail.mit.edu/cb/viral-mutation/data.tar.gz\n",
    "# !tar xvf data.tar.gz\n",
    "### https://github.com/brianhie/viral-mutation/blob/81c80d41671670eb58cc46e957a1b0c4bf14856a/bin/escape.py#L5\n",
    "# # pd.read_csv('data/influenza/escape_doud2018/pos_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "5mfHmXg0kJjV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mutations</th>\n",
       "      <th>Semantic change</th>\n",
       "      <th>Grammaticality</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H69del,V70del,Y144del,N501Y,A570D,P681H,T716I,...</td>\n",
       "      <td>2.0900</td>\n",
       "      <td>-4.426438</td>\n",
       "      <td>B.1.1.7</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D80A,D215G,K417N,E484K,N501Y,A701V</td>\n",
       "      <td>2.3320</td>\n",
       "      <td>-3.571184</td>\n",
       "      <td>V501.V2</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F140del,Y248del,249insK,249insT,249insR,249ins...</td>\n",
       "      <td>2.5590</td>\n",
       "      <td>-5.231962</td>\n",
       "      <td>PT188-EM</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V3I,D614G</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>-1.438198</td>\n",
       "      <td>null0</td>\n",
       "      <td>MFIFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L5F,T22I</td>\n",
       "      <td>1.0260</td>\n",
       "      <td>-2.518009</td>\n",
       "      <td>null1</td>\n",
       "      <td>MFVFFVLLPLVSSQCVNLTTRIQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>L8V</td>\n",
       "      <td>0.4204</td>\n",
       "      <td>-2.274710</td>\n",
       "      <td>null906</td>\n",
       "      <td>MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>L8V,D138Y</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>-3.060831</td>\n",
       "      <td>null907</td>\n",
       "      <td>MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>L8W,D614G</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>-2.423046</td>\n",
       "      <td>null908</td>\n",
       "      <td>MFVFLVLWPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>F2L</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>-2.516092</td>\n",
       "      <td>null909</td>\n",
       "      <td>MLVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>F2L,D614G</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>-1.347095</td>\n",
       "      <td>null910</td>\n",
       "      <td>MLVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Mutations  Semantic change  \\\n",
       "0    H69del,V70del,Y144del,N501Y,A570D,P681H,T716I,...           2.0900   \n",
       "1                   D80A,D215G,K417N,E484K,N501Y,A701V           2.3320   \n",
       "2    F140del,Y248del,249insK,249insT,249insR,249ins...           2.5590   \n",
       "3                                            V3I,D614G           0.7217   \n",
       "4                                             L5F,T22I           1.0260   \n",
       "..                                                 ...              ...   \n",
       "909                                                L8V           0.4204   \n",
       "910                                          L8V,D138Y           0.9610   \n",
       "911                                          L8W,D614G           0.9240   \n",
       "912                                                F2L           0.5740   \n",
       "913                                          F2L,D614G           0.9770   \n",
       "\n",
       "     Grammaticality        ID  \\\n",
       "0         -4.426438   B.1.1.7   \n",
       "1         -3.571184   V501.V2   \n",
       "2         -5.231962  PT188-EM   \n",
       "3         -1.438198     null0   \n",
       "4         -2.518009     null1   \n",
       "..              ...       ...   \n",
       "909       -2.274710   null906   \n",
       "910       -3.060831   null907   \n",
       "911       -2.423046   null908   \n",
       "912       -2.516092   null909   \n",
       "913       -1.347095   null910   \n",
       "\n",
       "                                              Sequence  \n",
       "0    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "1    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "2    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "3    MFIFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "4    MFVFFVLLPLVSSQCVNLTTRIQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "..                                                 ...  \n",
       "909  MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "910  MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "911  MFVFLVLWPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "912  MLVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "913  MLVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...  \n",
       "\n",
       "[914 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ex = pd.read_csv(\"https://raw.githubusercontent.com/brianhie/viral-mutation/master/examples/example_results.txt\",sep=\"\\t\",header=0)\n",
    "df_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "zrDjcxEXlkuv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Semantic change  Grammaticality  base_pred_vir  model_pred_vir  \\\n",
      "count          914.000         904.000        914.000           914.0   \n",
      "mean             1.062          -2.744          0.506             1.0   \n",
      "std              0.317           1.197          0.000             0.0   \n",
      "min              0.292          -7.777          0.504             1.0   \n",
      "25%              0.873          -3.292          0.505             1.0   \n",
      "50%              1.047          -2.452          0.506             1.0   \n",
      "75%              1.230          -1.929          0.506             1.0   \n",
      "max              2.684          -0.178          0.507             1.0   \n",
      "\n",
      "       model_pred_hum  model_pred_hum_delta  \n",
      "count           914.0                 914.0  \n",
      "mean              0.0                   0.0  \n",
      "std               0.0                   0.0  \n",
      "min               0.0                   0.0  \n",
      "25%               0.0                   0.0  \n",
      "50%               0.0                   0.0  \n",
      "75%               0.0                   0.0  \n",
      "max               0.0                   0.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semantic change</th>\n",
       "      <th>Grammaticality</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Semantic change</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grammaticality</th>\n",
       "      <td>0.256</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_pred_vir</th>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_vir</th>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum</th>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Semantic change  Grammaticality  base_pred_vir  \\\n",
       "Semantic change                 1.000           0.256         -0.099   \n",
       "Grammaticality                  0.256           1.000         -0.272   \n",
       "base_pred_vir                  -0.099          -0.272          1.000   \n",
       "model_pred_vir                  0.080          -0.033         -0.010   \n",
       "model_pred_hum                 -0.080           0.033          0.010   \n",
       "model_pred_hum_delta              NaN             NaN            NaN   \n",
       "\n",
       "                      model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
       "Semantic change                0.080          -0.080                   NaN  \n",
       "Grammaticality                -0.033           0.033                   NaN  \n",
       "base_pred_vir                 -0.010           0.010                   NaN  \n",
       "model_pred_vir                 1.000          -1.000                   NaN  \n",
       "model_pred_hum                -1.000           1.000                   NaN  \n",
       "model_pred_hum_delta             NaN             NaN                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ex = get_escaper_scores(df_ex,trained_model=model,base_model=base_model,seqColName=\"Sequence\",truncate_cao=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "YWgPv0OSsGsm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mutations</th>\n",
       "      <th>Semantic change</th>\n",
       "      <th>Grammaticality</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H69del,V70del,Y144del,N501Y,A570D,P681H,T716I,...</td>\n",
       "      <td>2.0900</td>\n",
       "      <td>-4.426438</td>\n",
       "      <td>B.1.1.7</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.504989</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D80A,D215G,K417N,E484K,N501Y,A701V</td>\n",
       "      <td>2.3320</td>\n",
       "      <td>-3.571184</td>\n",
       "      <td>V501.V2</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.505150</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F140del,Y248del,249insK,249insT,249insR,249ins...</td>\n",
       "      <td>2.5590</td>\n",
       "      <td>-5.231962</td>\n",
       "      <td>PT188-EM</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.506469</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V3I,D614G</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>-1.438198</td>\n",
       "      <td>null0</td>\n",
       "      <td>MFIFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.503845</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L5F,T22I</td>\n",
       "      <td>1.0260</td>\n",
       "      <td>-2.518009</td>\n",
       "      <td>null1</td>\n",
       "      <td>MFVFFVLLPLVSSQCVNLTTRIQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.505356</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>L8V</td>\n",
       "      <td>0.4204</td>\n",
       "      <td>-2.274710</td>\n",
       "      <td>null906</td>\n",
       "      <td>MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.505571</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>L8V,D138Y</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>-3.060831</td>\n",
       "      <td>null907</td>\n",
       "      <td>MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.505625</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>L8W,D614G</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>-2.423046</td>\n",
       "      <td>null908</td>\n",
       "      <td>MFVFLVLWPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.505005</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>F2L</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>-2.516092</td>\n",
       "      <td>null909</td>\n",
       "      <td>MLVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.505806</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>F2L,D614G</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>-1.347095</td>\n",
       "      <td>null910</td>\n",
       "      <td>MLVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>0.505401</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Mutations  Semantic change  \\\n",
       "0    H69del,V70del,Y144del,N501Y,A570D,P681H,T716I,...           2.0900   \n",
       "1                   D80A,D215G,K417N,E484K,N501Y,A701V           2.3320   \n",
       "2    F140del,Y248del,249insK,249insT,249insR,249ins...           2.5590   \n",
       "3                                            V3I,D614G           0.7217   \n",
       "4                                             L5F,T22I           1.0260   \n",
       "..                                                 ...              ...   \n",
       "909                                                L8V           0.4204   \n",
       "910                                          L8V,D138Y           0.9610   \n",
       "911                                          L8W,D614G           0.9240   \n",
       "912                                                F2L           0.5740   \n",
       "913                                          F2L,D614G           0.9770   \n",
       "\n",
       "     Grammaticality        ID  \\\n",
       "0         -4.426438   B.1.1.7   \n",
       "1         -3.571184   V501.V2   \n",
       "2         -5.231962  PT188-EM   \n",
       "3         -1.438198     null0   \n",
       "4         -2.518009     null1   \n",
       "..              ...       ...   \n",
       "909       -2.274710   null906   \n",
       "910       -3.060831   null907   \n",
       "911       -2.423046   null908   \n",
       "912       -2.516092   null909   \n",
       "913       -1.347095   null910   \n",
       "\n",
       "                                              Sequence  base_pred_vir  \\\n",
       "0    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.504989   \n",
       "1    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.505150   \n",
       "2    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.506469   \n",
       "3    MFIFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.503845   \n",
       "4    MFVFFVLLPLVSSQCVNLTTRIQLPPAYTNSFTRGVYYPDKVFRSS...       0.505356   \n",
       "..                                                 ...            ...   \n",
       "909  MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.505571   \n",
       "910  MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.505625   \n",
       "911  MFVFLVLWPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.505005   \n",
       "912  MLVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.505806   \n",
       "913  MLVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...       0.505401   \n",
       "\n",
       "     model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
       "0          0.999961        0.000039                   0.0  \n",
       "1          0.999961        0.000039                   0.0  \n",
       "2          0.999962        0.000038                   0.0  \n",
       "3          0.999961        0.000039                   0.0  \n",
       "4          0.999957        0.000043                   0.0  \n",
       "..              ...             ...                   ...  \n",
       "909        0.999957        0.000043                   0.0  \n",
       "910        0.999960        0.000040                   0.0  \n",
       "911        0.999957        0.000043                   0.0  \n",
       "912        0.999962        0.000038                   0.0  \n",
       "913        0.999961        0.000039                   0.0  \n",
       "\n",
       "[914 rows x 9 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IEDB epitopes\n",
    "*lots of (short) linear epitopes\n",
    "* humans, viruses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epitopes - IEDB ID         1105596\n",
      "Epitopes - Epitope         1105596\n",
      "Epitopes - Antigen           27807\n",
      "Epitopes - Organism              1\n",
      "Epitopes - # References         75\n",
      "Epitopes - # Assays            264\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epitopes - IEDB ID</th>\n",
       "      <th>Epitopes - Epitope</th>\n",
       "      <th>Epitopes - Antigen</th>\n",
       "      <th>Epitopes - Organism</th>\n",
       "      <th>Epitopes - # References</th>\n",
       "      <th>Epitopes - # Assays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>AAAAAAAAAAAAA</td>\n",
       "      <td>Solute carrier family 12 member 2</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>AAAAAIFVI</td>\n",
       "      <td>MHC class I polypeptide-related sequence A (Un...</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>AAAAALDKKQRNFDKILA</td>\n",
       "      <td>Myosin-7</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>AAEYWNSQKEVLER</td>\n",
       "      <td>HLA-DQB1*03:02 chain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>AAGIGILTV</td>\n",
       "      <td>Melanoma antigen recognized by T-cells 1</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>42</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105591</th>\n",
       "      <td>2253039</td>\n",
       "      <td>LTVDKSRWQQGNVFSC</td>\n",
       "      <td>Immunoglobulin heavy constant gamma 1</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105592</th>\n",
       "      <td>2253042</td>\n",
       "      <td>LYSKLTVDKSRWQQGNVFS + SCM(K4, K9)</td>\n",
       "      <td>Immunoglobulin heavy constant gamma 1</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105593</th>\n",
       "      <td>2253050</td>\n",
       "      <td>NGSGSGKWEGGPSK</td>\n",
       "      <td>Potassium voltage-gated channel subfamily H me...</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105594</th>\n",
       "      <td>2253058</td>\n",
       "      <td>PPMMYPHPAYP</td>\n",
       "      <td>Galectin-9</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105595</th>\n",
       "      <td>2253065</td>\n",
       "      <td>RDELTKNQVSLTCLVK</td>\n",
       "      <td>Immunoglobulin heavy constant gamma 1</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1105596 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Epitopes - IEDB ID                 Epitopes - Epitope  \\\n",
       "0                         2                      AAAAAAAAAAAAA   \n",
       "1                        10                          AAAAAIFVI   \n",
       "2                        11                 AAAAALDKKQRNFDKILA   \n",
       "3                       129                     AAEYWNSQKEVLER   \n",
       "4                       155                          AAGIGILTV   \n",
       "...                     ...                                ...   \n",
       "1105591             2253039                   LTVDKSRWQQGNVFSC   \n",
       "1105592             2253042  LYSKLTVDKSRWQQGNVFS + SCM(K4, K9)   \n",
       "1105593             2253050                     NGSGSGKWEGGPSK   \n",
       "1105594             2253058                        PPMMYPHPAYP   \n",
       "1105595             2253065                   RDELTKNQVSLTCLVK   \n",
       "\n",
       "                                        Epitopes - Antigen  \\\n",
       "0                        Solute carrier family 12 member 2   \n",
       "1        MHC class I polypeptide-related sequence A (Un...   \n",
       "2                                                 Myosin-7   \n",
       "3                                     HLA-DQB1*03:02 chain   \n",
       "4                 Melanoma antigen recognized by T-cells 1   \n",
       "...                                                    ...   \n",
       "1105591              Immunoglobulin heavy constant gamma 1   \n",
       "1105592              Immunoglobulin heavy constant gamma 1   \n",
       "1105593  Potassium voltage-gated channel subfamily H me...   \n",
       "1105594                                         Galectin-9   \n",
       "1105595              Immunoglobulin heavy constant gamma 1   \n",
       "\n",
       "          Epitopes - Organism  Epitopes - # References  Epitopes - # Assays  \n",
       "0        Homo sapiens (human)                        3                    3  \n",
       "1        Homo sapiens (human)                        2                    4  \n",
       "2        Homo sapiens (human)                        1                    1  \n",
       "3                         NaN                        2                    2  \n",
       "4        Homo sapiens (human)                       42                  121  \n",
       "...                       ...                      ...                  ...  \n",
       "1105591  Homo sapiens (human)                        1                   13  \n",
       "1105592  Homo sapiens (human)                        1                    2  \n",
       "1105593  Homo sapiens (human)                        1                    3  \n",
       "1105594  Homo sapiens (human)                        1                   12  \n",
       "1105595  Homo sapiens (human)                        1                   16  \n",
       "\n",
       "[1105596 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iedb_human = pd.read_csv(\"iedb_human_epitopes.csv\",compression=\"zip\").drop_duplicates(subset=[\"Epitopes - Epitope\"])\n",
    "## raw - 1.1M seqs\n",
    "print(df_iedb_human.nunique())\n",
    "df_iedb_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1105596.0\n",
       "mean           3.3\n",
       "std            8.0\n",
       "min            1.0\n",
       "25%            1.0\n",
       "50%            1.0\n",
       "75%            3.0\n",
       "max          565.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iedb_human[['Epitopes - # References','Epitopes - # Assays']].max(axis=1).describe().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter for higher confidence cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445355\n",
      "416466\n"
     ]
    }
   ],
   "source": [
    "df_iedb_human = df_iedb_human.loc[df_iedb_human[['Epitopes - # References','Epitopes - # Assays']].max(axis=1)>1]\n",
    "print(df_iedb_human.shape[0])\n",
    "df_iedb_human = df_iedb_human.loc[~df_iedb_human[\"Epitopes - Epitope\"].str.contains(\"[\\+ ]\")]\n",
    "print(df_iedb_human.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epitopes - IEDB ID</th>\n",
       "      <th>Epitopes - Epitope</th>\n",
       "      <th>Epitopes - Antigen</th>\n",
       "      <th>Epitopes - Organism</th>\n",
       "      <th>Epitopes - # References</th>\n",
       "      <th>Epitopes - # Assays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>AAAAAAAAAAAAA</td>\n",
       "      <td>Solute carrier family 12 member 2</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>AAAAAIFVI</td>\n",
       "      <td>MHC class I polypeptide-related sequence A (Un...</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>AAEYWNSQKEVLER</td>\n",
       "      <td>HLA-DQB1*03:02 chain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>AAGIGILTV</td>\n",
       "      <td>Melanoma antigen recognized by T-cells 1</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>42</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>368</td>\n",
       "      <td>AAPPVAPA</td>\n",
       "      <td>Cellular tumor antigen p53 (UniProt:A0A0U1RQC9)</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105590</th>\n",
       "      <td>2253021</td>\n",
       "      <td>KDTLMISRTPEVTCVV</td>\n",
       "      <td>Immunoglobulin heavy constant gamma 1</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105591</th>\n",
       "      <td>2253039</td>\n",
       "      <td>LTVDKSRWQQGNVFSC</td>\n",
       "      <td>Immunoglobulin heavy constant gamma 1</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105593</th>\n",
       "      <td>2253050</td>\n",
       "      <td>NGSGSGKWEGGPSK</td>\n",
       "      <td>Potassium voltage-gated channel subfamily H me...</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105594</th>\n",
       "      <td>2253058</td>\n",
       "      <td>PPMMYPHPAYP</td>\n",
       "      <td>Galectin-9</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105595</th>\n",
       "      <td>2253065</td>\n",
       "      <td>RDELTKNQVSLTCLVK</td>\n",
       "      <td>Immunoglobulin heavy constant gamma 1</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416466 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Epitopes - IEDB ID Epitopes - Epitope  \\\n",
       "0                         2      AAAAAAAAAAAAA   \n",
       "1                        10          AAAAAIFVI   \n",
       "3                       129     AAEYWNSQKEVLER   \n",
       "4                       155          AAGIGILTV   \n",
       "10                      368           AAPPVAPA   \n",
       "...                     ...                ...   \n",
       "1105590             2253021   KDTLMISRTPEVTCVV   \n",
       "1105591             2253039   LTVDKSRWQQGNVFSC   \n",
       "1105593             2253050     NGSGSGKWEGGPSK   \n",
       "1105594             2253058        PPMMYPHPAYP   \n",
       "1105595             2253065   RDELTKNQVSLTCLVK   \n",
       "\n",
       "                                        Epitopes - Antigen  \\\n",
       "0                        Solute carrier family 12 member 2   \n",
       "1        MHC class I polypeptide-related sequence A (Un...   \n",
       "3                                     HLA-DQB1*03:02 chain   \n",
       "4                 Melanoma antigen recognized by T-cells 1   \n",
       "10         Cellular tumor antigen p53 (UniProt:A0A0U1RQC9)   \n",
       "...                                                    ...   \n",
       "1105590              Immunoglobulin heavy constant gamma 1   \n",
       "1105591              Immunoglobulin heavy constant gamma 1   \n",
       "1105593  Potassium voltage-gated channel subfamily H me...   \n",
       "1105594                                         Galectin-9   \n",
       "1105595              Immunoglobulin heavy constant gamma 1   \n",
       "\n",
       "          Epitopes - Organism  Epitopes - # References  Epitopes - # Assays  \n",
       "0        Homo sapiens (human)                        3                    3  \n",
       "1        Homo sapiens (human)                        2                    4  \n",
       "3                         NaN                        2                    2  \n",
       "4        Homo sapiens (human)                       42                  121  \n",
       "10       Homo sapiens (human)                        1                    5  \n",
       "...                       ...                      ...                  ...  \n",
       "1105590  Homo sapiens (human)                        1                   18  \n",
       "1105591  Homo sapiens (human)                        1                   13  \n",
       "1105593  Homo sapiens (human)                        1                    3  \n",
       "1105594  Homo sapiens (human)                        1                   12  \n",
       "1105595  Homo sapiens (human)                        1                   16  \n",
       "\n",
       "[416466 rows x 6 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iedb_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    416466.0\n",
       "mean         12.0\n",
       "std           4.0\n",
       "min           2.0\n",
       "25%           9.0\n",
       "50%          10.0\n",
       "75%          15.0\n",
       "max          53.0\n",
       "Name: Epitopes - Epitope, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iedb_human[\"Epitopes - Epitope\"].str.len().describe().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Epitopes - IEDB ID  Epitopes - # References  Epitopes - # Assays  \\\n",
      "count           50123.000                50123.000            50123.000   \n",
      "mean           898881.882                    4.033                7.028   \n",
      "std            417955.496                    4.722               12.472   \n",
      "min              1956.000                    1.000                2.000   \n",
      "25%            574416.000                    2.000                2.000   \n",
      "50%            865110.000                    2.000                3.000   \n",
      "75%           1182225.000                    4.000                7.000   \n",
      "max           2253058.000                   73.000              391.000   \n",
      "\n",
      "       base_pred_vir  model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
      "count      50123.000       50123.000       50123.000             50123.000  \n",
      "mean           0.514           0.286           0.714                -0.190  \n",
      "std            0.004           0.285           0.285                 0.285  \n",
      "min            0.486           0.000           0.000                -0.904  \n",
      "25%            0.511           0.061           0.559                -0.345  \n",
      "50%            0.514           0.172           0.828                -0.076  \n",
      "75%            0.516           0.441           0.939                 0.035  \n",
      "max            0.531           1.000           1.000                 0.096  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epitopes - IEDB ID</th>\n",
       "      <th>Epitopes - # References</th>\n",
       "      <th>Epitopes - # Assays</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Epitopes - IEDB ID</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epitopes - # References</th>\n",
       "      <td>-0.436</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epitopes - # Assays</th>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_pred_vir</th>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_vir</th>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum</th>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Epitopes - IEDB ID  Epitopes - # References  \\\n",
       "Epitopes - IEDB ID                    1.000                   -0.436   \n",
       "Epitopes - # References              -0.436                    1.000   \n",
       "Epitopes - # Assays                  -0.274                    0.733   \n",
       "base_pred_vir                        -0.085                    0.090   \n",
       "model_pred_vir                       -0.029                    0.027   \n",
       "model_pred_hum                        0.029                   -0.027   \n",
       "model_pred_hum_delta                  0.029                   -0.027   \n",
       "\n",
       "                         Epitopes - # Assays  base_pred_vir  model_pred_vir  \\\n",
       "Epitopes - IEDB ID                    -0.274         -0.085          -0.029   \n",
       "Epitopes - # References                0.733          0.090           0.027   \n",
       "Epitopes - # Assays                    1.000          0.020           0.026   \n",
       "base_pred_vir                          0.020          1.000          -0.140   \n",
       "model_pred_vir                         0.026         -0.140           1.000   \n",
       "model_pred_hum                        -0.026          0.140          -1.000   \n",
       "model_pred_hum_delta                  -0.026          0.140          -1.000   \n",
       "\n",
       "                         model_pred_hum  model_pred_hum_delta  \n",
       "Epitopes - IEDB ID                0.029                 0.029  \n",
       "Epitopes - # References          -0.027                -0.027  \n",
       "Epitopes - # Assays              -0.026                -0.026  \n",
       "base_pred_vir                     0.140                 0.140  \n",
       "model_pred_vir                   -1.000                -1.000  \n",
       "model_pred_hum                    1.000                 1.000  \n",
       "model_pred_hum_delta              1.000                 1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epitopes - IEDB ID</th>\n",
       "      <th>Epitopes - Epitope</th>\n",
       "      <th>Epitopes - Antigen</th>\n",
       "      <th>Epitopes - Organism</th>\n",
       "      <th>Epitopes - # References</th>\n",
       "      <th>Epitopes - # Assays</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106966</th>\n",
       "      <td>511040</td>\n",
       "      <td>AGVETTTPSKQSNN</td>\n",
       "      <td>Immunoglobulin lambda constant 3</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.515025</td>\n",
       "      <td>0.135690</td>\n",
       "      <td>0.864310</td>\n",
       "      <td>-0.0397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42071</th>\n",
       "      <td>433553</td>\n",
       "      <td>YTDALLKPSASQY</td>\n",
       "      <td>Centrosome-associated protein 350</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.507247</td>\n",
       "      <td>0.286568</td>\n",
       "      <td>0.713432</td>\n",
       "      <td>-0.1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684100</th>\n",
       "      <td>1293810</td>\n",
       "      <td>VEYDEFTTLM</td>\n",
       "      <td>Nesprin-2 (UniProt:Q8WXH0)</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.513455</td>\n",
       "      <td>0.934873</td>\n",
       "      <td>0.065128</td>\n",
       "      <td>-0.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547712</th>\n",
       "      <td>1156718</td>\n",
       "      <td>LHSLVGQHILSVQQFT</td>\n",
       "      <td>CAD protein (UniProt:P27708)</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.518394</td>\n",
       "      <td>0.744656</td>\n",
       "      <td>0.255344</td>\n",
       "      <td>-0.6487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599355</th>\n",
       "      <td>1208609</td>\n",
       "      <td>ETAPTTVDR</td>\n",
       "      <td>Lambda-crystallin homolog</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.514492</td>\n",
       "      <td>0.927888</td>\n",
       "      <td>0.072112</td>\n",
       "      <td>-0.8319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45315</th>\n",
       "      <td>437517</td>\n",
       "      <td>GEDKGGYVI</td>\n",
       "      <td>Phenylalanine--tRNA ligase beta subunit</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>0.516946</td>\n",
       "      <td>0.870157</td>\n",
       "      <td>0.129843</td>\n",
       "      <td>-0.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257921</th>\n",
       "      <td>732323</td>\n",
       "      <td>YALPHAIL</td>\n",
       "      <td>Beta-actin-like protein 2</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>15</td>\n",
       "      <td>113</td>\n",
       "      <td>0.510863</td>\n",
       "      <td>0.297878</td>\n",
       "      <td>0.702122</td>\n",
       "      <td>-0.2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298970</th>\n",
       "      <td>838654</td>\n",
       "      <td>TEVAIVVKY</td>\n",
       "      <td>Piezo-type mechanosensitive ion channel compon...</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.513928</td>\n",
       "      <td>0.840783</td>\n",
       "      <td>0.159217</td>\n",
       "      <td>-0.7448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195819</th>\n",
       "      <td>637268</td>\n",
       "      <td>SLYIRPTFI</td>\n",
       "      <td>Branched-chain-amino-acid aminotransferase, cy...</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.514385</td>\n",
       "      <td>0.852445</td>\n",
       "      <td>0.147555</td>\n",
       "      <td>-0.7564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615209</th>\n",
       "      <td>1224516</td>\n",
       "      <td>GQVETIVSF</td>\n",
       "      <td>B-cell CLL/lymphoma 9 protein</td>\n",
       "      <td>Homo sapiens (human)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.515406</td>\n",
       "      <td>0.057918</td>\n",
       "      <td>0.942082</td>\n",
       "      <td>0.0381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50123 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Epitopes - IEDB ID Epitopes - Epitope  \\\n",
       "106966              511040     AGVETTTPSKQSNN   \n",
       "42071               433553      YTDALLKPSASQY   \n",
       "684100             1293810         VEYDEFTTLM   \n",
       "547712             1156718   LHSLVGQHILSVQQFT   \n",
       "599355             1208609          ETAPTTVDR   \n",
       "...                    ...                ...   \n",
       "45315               437517          GEDKGGYVI   \n",
       "257921              732323           YALPHAIL   \n",
       "298970              838654          TEVAIVVKY   \n",
       "195819              637268          SLYIRPTFI   \n",
       "615209             1224516          GQVETIVSF   \n",
       "\n",
       "                                       Epitopes - Antigen  \\\n",
       "106966                   Immunoglobulin lambda constant 3   \n",
       "42071                   Centrosome-associated protein 350   \n",
       "684100                         Nesprin-2 (UniProt:Q8WXH0)   \n",
       "547712                       CAD protein (UniProt:P27708)   \n",
       "599355                          Lambda-crystallin homolog   \n",
       "...                                                   ...   \n",
       "45315             Phenylalanine--tRNA ligase beta subunit   \n",
       "257921                          Beta-actin-like protein 2   \n",
       "298970  Piezo-type mechanosensitive ion channel compon...   \n",
       "195819  Branched-chain-amino-acid aminotransferase, cy...   \n",
       "615209                      B-cell CLL/lymphoma 9 protein   \n",
       "\n",
       "         Epitopes - Organism  Epitopes - # References  Epitopes - # Assays  \\\n",
       "106966  Homo sapiens (human)                        2                    2   \n",
       "42071   Homo sapiens (human)                       10                   12   \n",
       "684100  Homo sapiens (human)                        1                    2   \n",
       "547712  Homo sapiens (human)                        2                    4   \n",
       "599355  Homo sapiens (human)                        2                    2   \n",
       "...                      ...                      ...                  ...   \n",
       "45315   Homo sapiens (human)                        9                   34   \n",
       "257921  Homo sapiens (human)                       15                  113   \n",
       "298970  Homo sapiens (human)                        4                    5   \n",
       "195819  Homo sapiens (human)                        5                    5   \n",
       "615209  Homo sapiens (human)                        1                    2   \n",
       "\n",
       "        base_pred_vir  model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
       "106966       0.515025        0.135690        0.864310               -0.0397  \n",
       "42071        0.507247        0.286568        0.713432               -0.1906  \n",
       "684100       0.513455        0.934873        0.065128               -0.8389  \n",
       "547712       0.518394        0.744656        0.255344               -0.6487  \n",
       "599355       0.514492        0.927888        0.072112               -0.8319  \n",
       "...               ...             ...             ...                   ...  \n",
       "45315        0.516946        0.870157        0.129843               -0.7742  \n",
       "257921       0.510863        0.297878        0.702122               -0.2019  \n",
       "298970       0.513928        0.840783        0.159217               -0.7448  \n",
       "195819       0.514385        0.852445        0.147555               -0.7564  \n",
       "615209       0.515406        0.057918        0.942082                0.0381  \n",
       "\n",
       "[50123 rows x 10 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iedb_human_preds = get_escaper_scores(df_iedb_human.sample(50_123).copy(),trained_model=model,base_model=base_model,seqColName=\"Epitopes - Epitope\",truncate_cao=False)\n",
    "df_iedb_human_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_iedb_human_preds[\"model_pred_hum\"].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epitopes - IEDB ID         138074\n",
      "Epitopes - Epitope         138074\n",
      "Epitopes - Antigen            844\n",
      "Epitopes - Organism           182\n",
      "Epitopes - # References        59\n",
      "Epitopes - # Assays           103\n",
      "dtype: int64\n",
      "58544\n",
      "416466\n"
     ]
    }
   ],
   "source": [
    "# \"E:\\Stuff\\Research\\datasets\\New Protein-Virus anom project\\iedb_vir_epitopes.csv.zip.csv\"\n",
    "df_iedb_vir = pd.read_csv(\"iedb_vir_epitopes.csv\",compression=\"zip\").drop_duplicates(subset=[\"Epitopes - Epitope\"])\n",
    "## raw - 138K seqs\n",
    "print(df_iedb_vir.nunique())\n",
    "# df_iedb_vir\n",
    "\n",
    "df_iedb_vir = df_iedb_vir.loc[df_iedb_vir[['Epitopes - # References','Epitopes - # Assays']].max(axis=1)>1]\n",
    "print(df_iedb_vir.shape[0])\n",
    "df_iedb_vir = df_iedb_vir.loc[~df_iedb_vir[\"Epitopes - Epitope\"].str.contains(\"[\\+ ]\")]\n",
    "print(df_iedb_human.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Epitopes - IEDB ID  Epitopes - # References  Epitopes - # Assays  \\\n",
      "count           50183.000                50183.000            50183.000   \n",
      "mean          1018706.387                    1.725                3.744   \n",
      "std            735345.206                    3.346                7.547   \n",
      "min                24.000                    1.000                2.000   \n",
      "25%            128499.500                    1.000                2.000   \n",
      "50%           1421182.000                    1.000                2.000   \n",
      "75%           1638948.500                    2.000                4.000   \n",
      "max           2253124.000                  352.000              869.000   \n",
      "\n",
      "       base_pred_vir  model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
      "count      50183.000       50183.000       50183.000             50183.000  \n",
      "mean           0.512           0.399           0.601                -0.332  \n",
      "std            0.004           0.329           0.329                 0.329  \n",
      "min            0.491           0.000           0.000                -0.933  \n",
      "25%            0.510           0.102           0.314                -0.619  \n",
      "50%            0.513           0.299           0.701                -0.232  \n",
      "75%            0.515           0.686           0.898                -0.035  \n",
      "max            0.531           1.000           1.000                 0.066  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epitopes - IEDB ID</th>\n",
       "      <th>Epitopes - # References</th>\n",
       "      <th>Epitopes - # Assays</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Epitopes - IEDB ID</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epitopes - # References</th>\n",
       "      <td>-0.191</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epitopes - # Assays</th>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_pred_vir</th>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.018</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_vir</th>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Epitopes - IEDB ID  Epitopes - # References  \\\n",
       "Epitopes - IEDB ID                    1.000                   -0.191   \n",
       "Epitopes - # References              -0.191                    1.000   \n",
       "Epitopes - # Assays                  -0.177                    0.857   \n",
       "base_pred_vir                        -0.095                    0.028   \n",
       "model_pred_vir                        0.002                   -0.012   \n",
       "model_pred_hum                       -0.002                    0.012   \n",
       "model_pred_hum_delta                 -0.002                    0.012   \n",
       "\n",
       "                         Epitopes - # Assays  base_pred_vir  model_pred_vir  \\\n",
       "Epitopes - IEDB ID                    -0.177         -0.095           0.002   \n",
       "Epitopes - # References                0.857          0.028          -0.012   \n",
       "Epitopes - # Assays                    1.000          0.018           0.004   \n",
       "base_pred_vir                          0.018          1.000          -0.140   \n",
       "model_pred_vir                         0.004         -0.140           1.000   \n",
       "model_pred_hum                        -0.004          0.140          -1.000   \n",
       "model_pred_hum_delta                  -0.004          0.140          -1.000   \n",
       "\n",
       "                         model_pred_hum  model_pred_hum_delta  \n",
       "Epitopes - IEDB ID               -0.002                -0.002  \n",
       "Epitopes - # References           0.012                 0.012  \n",
       "Epitopes - # Assays              -0.004                -0.004  \n",
       "base_pred_vir                     0.140                 0.140  \n",
       "model_pred_vir                   -1.000                -1.000  \n",
       "model_pred_hum                    1.000                 1.000  \n",
       "model_pred_hum_delta              1.000                 1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epitopes - IEDB ID</th>\n",
       "      <th>Epitopes - Epitope</th>\n",
       "      <th>Epitopes - Antigen</th>\n",
       "      <th>Epitopes - Organism</th>\n",
       "      <th>Epitopes - # References</th>\n",
       "      <th>Epitopes - # Assays</th>\n",
       "      <th>base_pred_vir</th>\n",
       "      <th>model_pred_vir</th>\n",
       "      <th>model_pred_hum</th>\n",
       "      <th>model_pred_hum_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98018</th>\n",
       "      <td>1542217</td>\n",
       "      <td>QVVDADSKIVQLSEI</td>\n",
       "      <td>Replicase polyprotein 1ab</td>\n",
       "      <td>SARS-CoV2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.516458</td>\n",
       "      <td>0.098773</td>\n",
       "      <td>0.901227</td>\n",
       "      <td>-0.0322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>34144</td>\n",
       "      <td>KVNSTLEQY</td>\n",
       "      <td>Replicase polyprotein 1ab</td>\n",
       "      <td>SARS-CoV1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.517998</td>\n",
       "      <td>0.085099</td>\n",
       "      <td>0.914901</td>\n",
       "      <td>-0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102134</th>\n",
       "      <td>1638757</td>\n",
       "      <td>KKEISNMLSIINKRK</td>\n",
       "      <td>Genome polyprotein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517632</td>\n",
       "      <td>0.984336</td>\n",
       "      <td>0.015664</td>\n",
       "      <td>-0.9177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23953</th>\n",
       "      <td>92534</td>\n",
       "      <td>EEVPNIIHEA</td>\n",
       "      <td>Pre-glycoprotein polyprotein GP complex</td>\n",
       "      <td>Mammarenavirus brazilense (Brazilian mammarena...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.513524</td>\n",
       "      <td>0.137532</td>\n",
       "      <td>0.862468</td>\n",
       "      <td>-0.0709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64442</th>\n",
       "      <td>1425395</td>\n",
       "      <td>DVVSIRSSNQGN</td>\n",
       "      <td>Non-structural protein ORF4b</td>\n",
       "      <td>Middle East respiratory syndrome-related coron...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.513790</td>\n",
       "      <td>0.426560</td>\n",
       "      <td>0.573440</td>\n",
       "      <td>-0.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127865</th>\n",
       "      <td>1711438</td>\n",
       "      <td>YYDDSQYYFNKDTGVI</td>\n",
       "      <td>Hemagglutinin-esterase</td>\n",
       "      <td>Betacoronavirus 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500488</td>\n",
       "      <td>0.981875</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>-0.9153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125757</th>\n",
       "      <td>1704459</td>\n",
       "      <td>VLSVDSVSEESQGNVV</td>\n",
       "      <td>ORF1ab polyprotein</td>\n",
       "      <td>Human coronavirus HKU1 (CoV-HKU1)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.516535</td>\n",
       "      <td>0.071591</td>\n",
       "      <td>0.928409</td>\n",
       "      <td>-0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>11611</td>\n",
       "      <td>EEFCDMLRL</td>\n",
       "      <td>Pre-glycoprotein polyprotein GP complex</td>\n",
       "      <td>Mammarenavirus choriomeningitidis (Lymphocytic...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.517114</td>\n",
       "      <td>0.614625</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>-0.5480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35480</th>\n",
       "      <td>190297</td>\n",
       "      <td>NILDRIITNAGTCTVSIG</td>\n",
       "      <td>Major core protein 4a precursor</td>\n",
       "      <td>Vaccinia virus (vaccinia virus VV)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.508239</td>\n",
       "      <td>0.890294</td>\n",
       "      <td>0.109706</td>\n",
       "      <td>-0.8237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37121</th>\n",
       "      <td>230716</td>\n",
       "      <td>DVIESSIGDSVSRALTHALPAPTGQNTQVSSHRLDTGK</td>\n",
       "      <td>Genome polyprotein</td>\n",
       "      <td>Enterovirus A (Coxsackievirus A)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.508422</td>\n",
       "      <td>0.322526</td>\n",
       "      <td>0.677474</td>\n",
       "      <td>-0.2559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50183 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Epitopes - IEDB ID                      Epitopes - Epitope  \\\n",
       "98018              1542217                         QVVDADSKIVQLSEI   \n",
       "7313                 34144                               KVNSTLEQY   \n",
       "102134             1638757                         KKEISNMLSIINKRK   \n",
       "23953                92534                              EEVPNIIHEA   \n",
       "64442              1425395                            DVVSIRSSNQGN   \n",
       "...                    ...                                     ...   \n",
       "127865             1711438                        YYDDSQYYFNKDTGVI   \n",
       "125757             1704459                        VLSVDSVSEESQGNVV   \n",
       "2298                 11611                               EEFCDMLRL   \n",
       "35480               190297                      NILDRIITNAGTCTVSIG   \n",
       "37121               230716  DVIESSIGDSVSRALTHALPAPTGQNTQVSSHRLDTGK   \n",
       "\n",
       "                             Epitopes - Antigen  \\\n",
       "98018                 Replicase polyprotein 1ab   \n",
       "7313                  Replicase polyprotein 1ab   \n",
       "102134                       Genome polyprotein   \n",
       "23953   Pre-glycoprotein polyprotein GP complex   \n",
       "64442              Non-structural protein ORF4b   \n",
       "...                                         ...   \n",
       "127865                   Hemagglutinin-esterase   \n",
       "125757                       ORF1ab polyprotein   \n",
       "2298    Pre-glycoprotein polyprotein GP complex   \n",
       "35480           Major core protein 4a precursor   \n",
       "37121                        Genome polyprotein   \n",
       "\n",
       "                                      Epitopes - Organism  \\\n",
       "98018                                           SARS-CoV2   \n",
       "7313                                            SARS-CoV1   \n",
       "102134                                                NaN   \n",
       "23953   Mammarenavirus brazilense (Brazilian mammarena...   \n",
       "64442   Middle East respiratory syndrome-related coron...   \n",
       "...                                                   ...   \n",
       "127865                                  Betacoronavirus 1   \n",
       "125757                  Human coronavirus HKU1 (CoV-HKU1)   \n",
       "2298    Mammarenavirus choriomeningitidis (Lymphocytic...   \n",
       "35480                  Vaccinia virus (vaccinia virus VV)   \n",
       "37121                    Enterovirus A (Coxsackievirus A)   \n",
       "\n",
       "        Epitopes - # References  Epitopes - # Assays  base_pred_vir  \\\n",
       "98018                         3                    6       0.516458   \n",
       "7313                          1                    4       0.517998   \n",
       "102134                        1                    3       0.517632   \n",
       "23953                         1                    2       0.513524   \n",
       "64442                         1                    2       0.513790   \n",
       "...                         ...                  ...            ...   \n",
       "127865                        1                    2       0.500488   \n",
       "125757                        1                    2       0.516535   \n",
       "2298                          2                    2       0.517114   \n",
       "35480                         1                    2       0.508239   \n",
       "37121                         1                    2       0.508422   \n",
       "\n",
       "        model_pred_vir  model_pred_hum  model_pred_hum_delta  \n",
       "98018         0.098773        0.901227               -0.0322  \n",
       "7313          0.085099        0.914901               -0.0185  \n",
       "102134        0.984336        0.015664               -0.9177  \n",
       "23953         0.137532        0.862468               -0.0709  \n",
       "64442         0.426560        0.573440               -0.3600  \n",
       "...                ...             ...                   ...  \n",
       "127865        0.981875        0.018125               -0.9153  \n",
       "125757        0.071591        0.928409               -0.0050  \n",
       "2298          0.614625        0.385375               -0.5480  \n",
       "35480         0.890294        0.109706               -0.8237  \n",
       "37121         0.322526        0.677474               -0.2559  \n",
       "\n",
       "[50183 rows x 10 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iedb_vir_preds = get_escaper_scores(df_iedb_vir.sample(50_183).copy(),trained_model=model,base_model=base_model,seqColName=\"Epitopes - Epitope\",truncate_cao=False)\n",
    "df_iedb_vir_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_iedb_vir_preds[\"model_pred_hum\"].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iedb_vir_preds[\"label\"]=\"vir\"\n",
    "df_iedb_human_preds[\"label\"]=\"hum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>model_pred_hum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98018</th>\n",
       "      <td>vir</td>\n",
       "      <td>0.901227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>vir</td>\n",
       "      <td>0.914901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102134</th>\n",
       "      <td>vir</td>\n",
       "      <td>0.015664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23953</th>\n",
       "      <td>vir</td>\n",
       "      <td>0.862468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64442</th>\n",
       "      <td>vir</td>\n",
       "      <td>0.573440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45315</th>\n",
       "      <td>hum</td>\n",
       "      <td>0.129843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257921</th>\n",
       "      <td>hum</td>\n",
       "      <td>0.702122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298970</th>\n",
       "      <td>hum</td>\n",
       "      <td>0.159217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195819</th>\n",
       "      <td>hum</td>\n",
       "      <td>0.147555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615209</th>\n",
       "      <td>hum</td>\n",
       "      <td>0.942082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100306 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  model_pred_hum\n",
       "98018    vir        0.901227\n",
       "7313     vir        0.914901\n",
       "102134   vir        0.015664\n",
       "23953    vir        0.862468\n",
       "64442    vir        0.573440\n",
       "...      ...             ...\n",
       "45315    hum        0.129843\n",
       "257921   hum        0.702122\n",
       "298970   hum        0.159217\n",
       "195819   hum        0.147555\n",
       "615209   hum        0.942082\n",
       "\n",
       "[100306 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iedbs = pd.concat([df_iedb_vir_preds[[\"label\",\"model_pred_hum\"]],df_iedb_human_preds[[\"label\",\"model_pred_hum\"]]])\n",
    "df_iedbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='model_pred_hum', ylabel='Density'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# https://stackoverflow.com/questions/28293028/plotting-grouped-data-in-same-plot-using-pandas\n",
    "# df_iedbs.groupby([\"label\"]).plot(kind='kde', ax=plt.gca())\n",
    "\n",
    "sns.kdeplot(data=df_iedbs, x=\"model_pred_hum\", hue=\"label\")#, bw_adjust=1, cut=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">model_pred_hum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hum</th>\n",
       "      <td>50123.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vir</th>\n",
       "      <td>50183.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_pred_hum                                        \n",
       "               count  mean   std  min   25%   50%   75%  max\n",
       "label                                                       \n",
       "hum          50123.0  0.71  0.28  0.0  0.56  0.83  0.94  1.0\n",
       "vir          50183.0  0.60  0.33  0.0  0.31  0.70  0.90  1.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iedbs.groupby(\"label\").describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1f6tWCmDttwj5GsdTavt7m-dIH1-2f1P5",
     "timestamp": 1706088386277
    },
    {
     "file_id": "18pa4xD0P5vwL-MX30nrkeye78W7403TZ",
     "timestamp": 1702551198722
    },
    {
     "file_id": "1uwM47KOjpzSn2TylouVCrTiGuskjQtEd",
     "timestamp": 1690279074762
    },
    {
     "file_id": "1_4meskHUbh7-dkjF-ajOT_wazp1vxzC6",
     "timestamp": 1630488037990
    },
    {
     "file_id": "1325niNI11d1AGvkudzFonUaYu-_IpRSv",
     "timestamp": 1629371463407
    },
    {
     "file_id": "1eeHOXM2csXDuY2ysmo-npc7dWtr9hcKJ",
     "timestamp": 1629281016353
    },
    {
     "file_id": "https://github.com/sacdallago/bio_embeddings/blob/develop/notebooks/embed_fasta_sequences.ipynb",
     "timestamp": 1629109653928
    }
   ]
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4380199,
     "sourceId": 7529659,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
